<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nktmemo_ja</title>
    <description>nktmemo provides interesting articles about Machine Learning and NLP. 
</description>
    <link>http://nktmemoja.github.io/</link>
    <atom:link href="http://nktmemoja.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 08 Jan 2016 04:50:25 +0900</pubDate>
    <lastBuildDate>Fri, 08 Jan 2016 04:50:25 +0900</lastBuildDate>
    <generator>Jekyll v3.0.0</generator>
    
      <item>
        <title>Hard-Margin Support Vector Machine (SVM)の定式化</title>
        <description>&lt;p&gt;&lt;a rel=&quot;nofollow&quot; href=&quot;http://www.amazon.co.jp/gp/product/4061529064/ref=as_li_ss_tl?ie=UTF8&amp;amp;camp=247&amp;amp;creative=7399&amp;amp;creativeASIN=4061529064&amp;amp;linkCode=as2&amp;amp;tag=nettodesyuu00-22&quot; target=&quot;_blank&quot;&gt;サポートベクトルマシン (機械学習プロフェッショナルシリーズ)&lt;/a&gt;&lt;img src=&quot;http://ir-jp.amazon-adsystem.com/e/ir?t=nettodesyuu00-22&amp;amp;l=as2&amp;amp;o=9&amp;amp;a=4061529064&quot; width=&quot;1&quot; height=&quot;1&quot; border=&quot;0&quot; alt=&quot;&quot; style=&quot;border:none !important; margin:0px !important;&quot; /&gt;
を読んでいます．
SVMについて，わかっている気になっていましたが，わかっていませんでした．
意外と奥が深いですね．というわけでその整理の意味も込めてのポスト．&lt;/p&gt;

&lt;p&gt;この記事ではハードマージンSVMを考えます．
ハードマージンSVMでは，与えられたデータは線形分離可能であると仮定します．
つまり，超平面&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{x})=\boldsymbol{w}^T \boldsymbol{x} + b&lt;/script&gt;で，与えられた訓練データがミスなく分離できることを仮定します．
このような超平面は複数存在すると考えられますが，
SVMでは，「マージンを最大化する超平面を求める」，というのはよくある説明ですね．&lt;/p&gt;

&lt;p&gt;ではまず，マージンの定義から入りましょう．
今，訓練データ&lt;script type=&quot;math/tex&quot;&gt;\{(\boldsymbol{x}_i,y_i)\}_{i=1}^n, \boldsymbol{x}_i \in \mathbb{R}^d, y_i \in \{-1,1\} \ \forall i=1, \ldots, n&lt;/script&gt;が与えられているとします．
マージンを，
超平面&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{x})=\boldsymbol{w}^T \boldsymbol{x} + b&lt;/script&gt;からもっとも近いサンプルまでの距離と定義します．
つまり，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
i^{*} = \mathop{\rm arg\,min}\limits_{1 \leq i \leq n} \ \frac{|\boldsymbol{w}^T \boldsymbol{x}_i + b|}{\|\boldsymbol{w}\|}
= \mathop{\rm arg\,min}\limits_{1 \leq i \leq n} \ |\boldsymbol{w}^T \boldsymbol{x}_i + b|
\end{align*}&lt;/script&gt;

&lt;p&gt;と定義すると，マージンは&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\frac{|\boldsymbol{w}^T \boldsymbol{x}_{i^{*}} + b|}{\|\boldsymbol{w}\|}
\end{align*}&lt;/script&gt;

&lt;p&gt;と表すことができます．
全ての訓練データを正しく分類しつつ，このマージンを最大化したいので，以下の最適化問題を解きます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\max_{\boldsymbol{w},b} &amp;\ \frac{|\boldsymbol{w}^T \boldsymbol{x}_{i^{*}} + b|}{\|\boldsymbol{w}\|} \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) &gt; 0 \ \forall i=1,\ldots ,n
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;分子が邪魔なので，これを以下のように書き換えます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\max_{\boldsymbol{w},b} &amp;\ \frac{1}{\|\boldsymbol{w}\|} \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) &gt; 0 \ \forall i=1,\ldots ,n \\
&amp;\ |\boldsymbol{w}^T \boldsymbol{x}_{i^{*}} + b |=1
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;二つの制約条件を一つにまとめると，以下のようになります．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\max_{\boldsymbol{w},b} &amp;\ \frac{1}{\|\boldsymbol{w}\|} \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1 \ \forall i=1,\ldots ,n \\
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;個人的にはここの変形が一番きつかったですね…．
なので軽く補足しときます．
以下の制約を書き換えていきます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
 y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) &gt; 0 \ \forall i=1,\ldots ,n \ \cdots (1) \\
 |\boldsymbol{w}^T \boldsymbol{x}_{i^{*}} + b |=1 \ \cdots (2)
\end{align}&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;i^{*}&lt;/script&gt;の定義から，(2)は以下のように書き換えられます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\ |\boldsymbol{w}^T \boldsymbol{x}_{i} + b| \geq 1  \ \forall i=1,\ldots ,n \ \cdots (2&#39;)
\end{align}&lt;/script&gt;

&lt;p&gt;ここで，(1)と(2’)を合体させたいのですが，
&lt;script type=&quot;math/tex&quot;&gt;y_i(\boldsymbol{w}^T \boldsymbol{x}_{i} + b) = |\boldsymbol{w}^T \boldsymbol{x}_{i} + b|&lt;/script&gt;
を示すことができれば良さそうです．
ここで，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) = \left\{
\begin{array}
\boldsymbol{w}^T \boldsymbol{x}_i + b &amp; (y_i=1) \\
-(\boldsymbol{w}^T \boldsymbol{x}_i + b) &amp; (y_i=-1)
\end{array}
\right.
\end{align*}, %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
|\boldsymbol{w}^T \boldsymbol{x}_i + b| = \left\{
\begin{array}
\boldsymbol{w}^T \boldsymbol{x}_i + b &amp; (\boldsymbol{w}^T \boldsymbol{x}_i + b \geq 0) \\
-(\boldsymbol{w}^T \boldsymbol{x}_i + b) &amp; (\boldsymbol{w}^T \boldsymbol{x}_i + b &lt; 0)
\end{array}
\right.
\end{align*}, %]]&gt;&lt;/script&gt;

&lt;p&gt;ですが，(1)より，&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}^T \boldsymbol{x}_i + b \geq 0&lt;/script&gt; は成り立たず，この文脈では必ず
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}^T \boldsymbol{x}_i + b &gt; 0&lt;/script&gt;となります．&lt;/p&gt;

&lt;p&gt;なので，&lt;script type=&quot;math/tex&quot;&gt;y_i=1 \Leftrightarrow \boldsymbol{w}^T \boldsymbol{x}_i + b &gt; 0&lt;/script&gt;と
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
y_i=-1 \Leftrightarrow \boldsymbol{w}^T \boldsymbol{x}_i + b &lt; 0 %]]&gt;&lt;/script&gt;を示すことにします．
すごく簡単すぎて示す必要もないかもしれませんが…．&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;y_i=1&lt;/script&gt;の時，(1)より，&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}^T \boldsymbol{x}_i + b &gt; 0&lt;/script&gt;．
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}^T \boldsymbol{x}_i + b &gt; 0&lt;/script&gt;の時，(1)と&lt;script type=&quot;math/tex&quot;&gt;y_i \in \{-1,1\}&lt;/script&gt;より，&lt;script type=&quot;math/tex&quot;&gt;y_i=1&lt;/script&gt;．
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
y_i=-1 \Leftrightarrow \boldsymbol{w}^T \boldsymbol{x}_i + b &lt; 0 %]]&gt;&lt;/script&gt;も同様．&lt;/p&gt;

&lt;p&gt;よって，
&lt;script type=&quot;math/tex&quot;&gt;y_i(\boldsymbol{w}^T \boldsymbol{x}_{i} + b) = |\boldsymbol{w}^T \boldsymbol{x}_{i} + b|&lt;/script&gt;．&lt;/p&gt;

&lt;p&gt;そういうわけで，(2’)は，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\ y_i(\boldsymbol{w}^T \boldsymbol{x}_{i} + b) \geq 1  \ \forall i=1,\ldots ,n \ \cdots (2&#39;&#39;)
\end{align}&lt;/script&gt;

&lt;p&gt;これで，(1)と(2’‘)を合体できますね．
最後に最大化と最小化を書き換えて，ノルムを2乗すれば，よく見るハードマージンSVMの最適化問題の完成です：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\min_{\boldsymbol{w},b} &amp;\ \|\boldsymbol{w}\|^2 \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1 \ \forall i=1,\ldots ,n 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;ここで，与えられたデータに対して，制約&lt;script type=&quot;math/tex&quot;&gt;y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1 \ \forall i=1,\ldots ,n&lt;/script&gt;を満たす&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;が存在しないかもしれません．
というより，現実問題ではそのような場合がほとんどだと考えられます．
そこで，ソフトマージンの考え方が出てきます．
これについてはまた後日書けたらと思います．&lt;/p&gt;
</description>
        <pubDate>Fri, 08 Jan 2016 00:30:29 +0900</pubDate>
        <link>http://nktmemoja.github.io/jekyll/update/2016/01/08/hardmarginsvmformulation.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/jekyll/update/2016/01/08/hardmarginsvmformulation.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>正例とラベル無しデータからの学習 (PU classification)</title>
        <description>&lt;p&gt;通常の2値分類問題では，正例と負例が与えられています． しかし扱う問題によっては，このようなデータを用意するのが困難な時があります． 例えば，抽出型のタスクです． 抽出型のタスクでは，抽出したい対象を正例と考えます． この場合の負例は「正例以外のデータ」と定義するほかありません． しかし，集めた正例に対し，それ以外のデータを負例と定義してしまうと， それ以外のデータに含まれる正例も負例として扱ってしまいます．&lt;/p&gt;

&lt;p&gt;このように負例を定義するのが難しい場合には，正例とラベルなしデータから学習する枠組み，PU classificationが有用です． PU classificationについては，Elkan and Noto 2008を参照していただければと思うのですが，少しだけ解説しておきます． 3つの確率変数&lt;script type=&quot;math/tex&quot;&gt;x,y,s&lt;/script&gt;を考えます．ここで，&lt;script type=&quot;math/tex&quot;&gt;x \in \mathbb{R}, y \in \{-1,1\}, s \in \{0,1\}&lt;/script&gt;だとします． &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;は入力，&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;はクラスラベル，そして&lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt;はデータがラベリングされるかどうかを表しています． 我々が欲しいのは，
&lt;script type=&quot;math/tex&quot;&gt;p(y|x)&lt;/script&gt;
ですが，PU classificationでは&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;は観測することができません． 我々のゴールは，&lt;script type=&quot;math/tex&quot;&gt;\{(x_i,s_i)\}_{i=1}^n&lt;/script&gt;から
&lt;script type=&quot;math/tex&quot;&gt;p(y|x)&lt;/script&gt;
を学習することです． 結果からいうと，2つの仮定をおくことで，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y=1|x) = \frac{p(s=1|x)}{p(s=1|y=1)}&lt;/script&gt;

&lt;p&gt;と表せます．
&lt;script type=&quot;math/tex&quot;&gt;p(s=1|x)&lt;/script&gt;
は与えられたデータから推定できます． そして，
&lt;script type=&quot;math/tex&quot;&gt;p(s=1|y=1)&lt;/script&gt;
は開発データから推定できます． 詳しくはElkan and Noto 2008の2章にまとめられています． 今回はElkan and Noto 2008の手法を用いてPU classificationを行っていきます．&lt;/p&gt;

&lt;p&gt;では，以下のような正解データを考えましょう． &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-true_labeled.png&quot; alt=&quot;true_labeled.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;このデータに対して，実際に与えられるのは以下のようなデータです． &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-pu_data.png&quot; alt=&quot;pu_data.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;このデータに対して，まずは通常のロジスティック回帰を適用してみます． なお，今回は負例が多いので，交差確認法には正例側のF値を用います． 結果は以下のようになりました． &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-result_of_tradclf1.png&quot; alt=&quot;result_of_tradclf.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ご覧のように，全て負例だと予測してしまいました． 次に，PU classificationを適用してみます． &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-result_of_puclassification.png&quot; alt=&quot;result_of_puclassification.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;正例とラベルなしデータから，うまく分類境界を学習できていることがわかります．&lt;/p&gt;

&lt;p&gt;デモ用のコードは以下に載せておきますのでぜひ試してみてください． ちなみに，非線形な分類境界を表現するための&lt;a href=&quot;https://gist.github.com/nkt1546789/e41199340f7a42c515be&quot; title=&quot;rbfmodel_wrapper.py&quot;&gt;rbfmodel_wrapper.py&lt;/a&gt; と PU Classificationのための&lt;a href=&quot;https://gist.github.com/nkt1546789/9fbbf2f450779bde60c3&quot; title=&quot;puwrapper.py&quot;&gt;puwrapper.py&lt;/a&gt; も合わせてDLしてください．&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/nkt1546789/e9421f06ea3a62bfbb8c&quot; title=&quot;https://gist.github.com/nkt1546789/e9421f06ea3a62bfbb8c&quot;&gt;https://gist.github.com/nkt1546789/e9421f06ea3a62bfbb8c&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Thu, 29 Oct 2015 21:47:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/machine%20learning/2015/10/29/29214700.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/machine%20learning/2015/10/29/29214700.html</guid>
        
        <category>Machine Learning</category>
        
        <category>PU classification</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Word2Vecを使った単語間関係分類</title>
        <description>&lt;p&gt;単語間には様々な関係があります． 今回は，単語間の関係をWord2Vecで学習させようと思います． Word2Vecにはアナロジーを捉えられるという話があります． あの有名な，king - man + woman = queen というやつですね． これは，king - man = queen - womanとも書けます． つまり，2語間の差が関係を表しており， この例だと，kingとmanの関係とqueenとwomanの関係が同じであると捉えることができます．&lt;/p&gt;

&lt;p&gt;さて，Word2Vecで学習したベクトル表現を使うと，差ベクトルがうまいこと関係を表すと書きましたが， 必ずしもそうなっているとは限りません． 加えて，ユーザが扱いたい関係とWord2Vecで学習した関係が一致しているとも限りません． そこで，今回も例のごとく教師あり学習を使います． ユーザは教師データを通して，扱いたい関係をアルゴリズムに伝えることができます．&lt;/p&gt;

&lt;p&gt;最初からあまり多くの関係を対象にするのはしんどいので，今回はis-a, has-a関係のみに着目します． これは，僕の理解では，柔道 is-a スポーツ，スポーツ has-a 柔道みたいなものだと思っています． まずは&lt;a href=&quot;https://gist.github.com/nkt1546789/a3b3a4c166fc1c0486a1&quot; title=&quot;training data&quot;&gt;training data&lt;/a&gt;を用意します． is-aとhas-aは反対の関係になっていると思うので，has-aのデータだけ用意します． この中には (スポーツ，野球)というhas-a関係を表す順序対がリストで格納されています． リスト内の順序対に対して差ベクトルを計算し，一つのデータとして扱います．&lt;/p&gt;

&lt;p&gt;コードは以下のようになりました．&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;training&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;gensim.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LogisticRegressionCV&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;/path/to/your/w2v_model&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ntr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ntr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ntr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Xtr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ytr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Xte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;yte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogisticRegressionCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Xtr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ytr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ypred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Xte&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yte&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ypred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; 0.99502487562189057&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;今回は厳密な実験はせずに，簡単に性能を見てみました． テストデータに対して，99%の精度を出すことができました． 以下簡単なテストデータへの予測例です．&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ypred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;has-a&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;is-a&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# results:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;ブルーベリー&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;果物&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;動物&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;モルモット&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;動物&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;ワタボウシタマリン&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;登山&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;ロデオ&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;動物&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;ユーラシアカワウソ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;フリーダイビング&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;競馬&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;ゴルフ&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;いかがでしょうか？うまく狙った関係が分類できていると思います． とりあえずはうまくいきました！これで成功です！ これがどこまで実用に耐えられるかはやってみないとわかりませんが．&lt;/p&gt;

</description>
        <pubDate>Tue, 27 Oct 2015 20:57:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/machine%20learning/2015/10/27/27205700.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/machine%20learning/2015/10/27/27205700.html</guid>
        
        <category>Machine Learning</category>
        
        <category>NLP</category>
        
        <category>python</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Word2Vec+教師あり次元削減で文書分類+単語分類</title>
        <description>&lt;p&gt;前回:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://nktmemo.wordpress.com/2015/09/29/%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E5%99%A8%E3%81%A7%E5%8D%98%E8%AA%9E%E5%88%86%E9%A1%9E%E3%82%92%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B/&quot; title=&quot;https://nktmemo.wordpress.com/2015/09/29/%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E5%99%A8%E3%81%A7%E5%8D%98%E8%AA%9E%E5%88%86%E9%A1%9E%E3%82%92%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B/&quot;&gt;文書分類器で単語分類をしてみる&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の続きです．&lt;/p&gt;

&lt;p&gt;まずは，前回のおさらい． 前回は，文書に対してはラベル付きデータが与えられており，単語についてはラベルなしデータが与えられているという設定を考えました． そして，文書と単語が同じ空間に存在すれば，半教師付き学習に帰着することを示しました． 詳しくは前回の記事を見ていただくとして，これからは半教師付き学習の設定で話を進めます．&lt;/p&gt;

&lt;p&gt;今回は，前回の記事でいう単語ベクトル集合&lt;script type=&quot;math/tex&quot;&gt;\{x_i\}_{i=n_d}^{n}&lt;/script&gt;をWord2Vecで学習させます． 食わせるコーパスは分類対象の文書集合です．&lt;/p&gt;

&lt;p&gt;その後，教師あり次元削減手法であるFisher Discriminant Analysis (FDA)を使って&lt;script type=&quot;math/tex&quot;&gt;B:\mathbb{R}^d\rightarrow\mathbb{R}^m&lt;/script&gt;を学習させます． これによって，Word2Vecで学習した単語ベクトルたちは，より低次元の空間に落とし込まれます． つまり，&lt;script type=&quot;math/tex&quot;&gt;z=Bx&lt;/script&gt;として，&lt;script type=&quot;math/tex&quot;&gt;\{(z_i,y_i)\}_{i=1}^{n_d}&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;\{z_i\}_{i=n_d}^{n}&lt;/script&gt;を得ます． 今回は，&lt;script type=&quot;math/tex&quot;&gt;m=c-1&lt;/script&gt;としました，ただし，&lt;script type=&quot;math/tex&quot;&gt;c&lt;/script&gt;はクラス数です．&lt;/p&gt;

&lt;p&gt;なぜこのような処理をするかというと，Word2Vecのような教師なし学習では，必ずしも「望ましい結果」が得られるとは限りません． なぜなら，「望ましい結果」についての情報を一切与えていないからです． 今回の目的は文書分類+単語分類です． この目的に対して，Word2Vecが必ずしも望ましい結果を返すとは限らないのです．&lt;/p&gt;

&lt;p&gt;そこで，教師あり次元削減を使います． FDAは，簡単にいうと，同じクラスに属するサンプルは近く，異なるクラスに属するサンプルは遠くなるよう，射影行列を学習します． ここでは，「望ましい結果」教師データとして与えるので，学習後の空間は分類という目的に対して望ましい空間になっていると期待できます．&lt;/p&gt;

&lt;p&gt;さて，あとは対して面白いことはしていません． &lt;script type=&quot;math/tex&quot;&gt;\{(z_i,y_i)\}_{i=1}^{n_d}&lt;/script&gt;で確率的分類器を学習させ，&lt;script type=&quot;math/tex&quot;&gt;\{z_i\}_{i=n_d}^{n}&lt;/script&gt;に対して予測をします．&lt;/p&gt;

&lt;p&gt;前回と同じデータを使って実験をしました． 結果の出力には同様にwordcloudを使わせてもらいました．&lt;/p&gt;

&lt;p&gt;ガールズ: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-girls.png&quot; alt=&quot;girls.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ニュース・ゴシップ: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-news1.png&quot; alt=&quot;news.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;エンタメ・カルチャー: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-entertainment1.png&quot; alt=&quot;entertainment.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;おでかけ・グルメ: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-spot1.png&quot; alt=&quot;spot.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;暮らし・アイデア: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-life1.png&quot; alt=&quot;life.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;レシピ: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-recipe1.png&quot; alt=&quot;recipe.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;カラダ: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-wellness1.png&quot; alt=&quot;wellness.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ビジネススキル: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-business1.png&quot; alt=&quot;business.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;IT・ガジェット: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-tech1.png&quot; alt=&quot;tech.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;デザイン・アート: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-design1.png&quot; alt=&quot;design.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;雑学: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-trivia1.png&quot; alt=&quot;trivia.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;おもしろ: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-humor1.png&quot; alt=&quot;humor.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;定番: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-popular1.png&quot; alt=&quot;popular.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;評価データがなくて定性的に評価するしかないのですが，前回と比べて，かなり改善されている気がします． 雑学とかおもしろ，定番なんかは定義がよくわからなくて判断しにくいですが，それ以外はうまく単語分類ができていると思います．&lt;/p&gt;

&lt;p&gt;今回は，Word2Vec+教師あり次元削減 (FDA) を使って文書分類器を作成し，それを使って単語分類をしてみました． 結果として，このアプローチはなかなか良いと感じました． 文書分類，単語分類については，これでひと段落した感じがします． 本当は単語分類なんかはマルチラベル分類問題として解くべくなのかもしれませんが，あまりこの問題に執着してもあれなので． 次は要約や，トレンド抽出なんかをやっていきたいなあなんて思っています．&lt;/p&gt;

&lt;p&gt;前回と今回はコードを載せていません． これはコードがなかなか複雑なためです． もし，見てみたいという方がいたら，コメントからでも，Twitterからでもなんでも良いので言ってください！ 読んでいただき，ありがとうございました．&lt;/p&gt;

</description>
        <pubDate>Tue, 06 Oct 2015 20:46:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/machine%20learning/2015/10/06/06204600.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/machine%20learning/2015/10/06/06204600.html</guid>
        
        <category>Machine Learning</category>
        
        <category>NLP</category>
        
        <category>python</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>文書分類器で単語分類をしてみる</title>
        <description>&lt;p&gt;keywords: 文書分類 (document classification）， 単語分類（word classification）， Pointwise mutual information&lt;/p&gt;

&lt;h2 id=&quot;sec-1&quot;&gt;はじめに&lt;/h2&gt;
&lt;p&gt;文書へのラベリングと単語へのラベリングはどちらが簡単だろう？ 例えば多くのニュースサイトではすでに文書は分類されている． しかし，単語が分類されているのは見たことがない． というより，そんなものを表に出してもあまり意味がないので表に出ていないのだろう． この状況を踏まえると，データをクロールする側からすると，ラベル付き文書データを入手するのは容易で， ラベル付き単語データを入手するのは困難だと言える．&lt;/p&gt;

&lt;p&gt;いま，文書データをクロールして，検索エンジンを作ることを考えよう． 各文書にはラベルが付いている． このラベル情報を活かせないか？ 例えばクエリにラベルが付いていれば，クエリと文書のラベルを見て，一致するものを出せばよい，あるいはそういう場合にスコアが高くなるように，検索エンジンのスコアを設計すれば良い． このように，単語へのラベリングはある程度需要があると推測される．&lt;/p&gt;

&lt;h2 id=&quot;sec-2&quot;&gt;定式化&lt;/h2&gt;

&lt;p&gt;さて，今回やるのは，ラベル付き文書データを使って，単語分類をしようというもの． つまり，持っているものは，&lt;script type=&quot;math/tex&quot;&gt;\{(d_i,y_i)\}_{i=1}^{n_d}&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;\{w_i\}_{i=1}^{n_w}&lt;/script&gt;， ただし，&lt;script type=&quot;math/tex&quot;&gt;d_i \in \mathcal{D}&lt;/script&gt;は文書，&lt;script type=&quot;math/tex&quot;&gt;y_i \in \mathcal{Y}&lt;/script&gt;は文書に対するラベル, &lt;script type=&quot;math/tex&quot;&gt;w_i \in \mathcal{W}&lt;/script&gt;は単語を意味する．&lt;/p&gt;

&lt;p&gt;ここで，もし単語と文書が同じ空間に存在すれば，文書分類器を使って単語分類ができると思われる． つまり，&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}=\mathcal{D}=\mathcal{W}&lt;/script&gt;とし，なんらかの変換&lt;script type=&quot;math/tex&quot;&gt;\phi:\mathcal{S} \rightarrow \mathcal{X}&lt;/script&gt;を定義すればよい． ここまで来れば，&lt;script type=&quot;math/tex&quot;&gt;x_i=\phi(d_i) \ \forall i=1,\ldots,n_d, \ x_{n_w+j}=\phi(w_j) \ \forall j=1,\ldots,n_w&lt;/script&gt;とし， &lt;script type=&quot;math/tex&quot;&gt;\{(x_i,y_i)\}_{i=1}^{n_d}&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;\{x_i\}_{i=n_d}^{n}&lt;/script&gt;を得る．ただし&lt;script type=&quot;math/tex&quot;&gt;n=n_d+n_w&lt;/script&gt;． こうして見てみると，単語と文書を同じ空間に写像すれば，これは半教師付き分類問題に帰着することがわかる．&lt;/p&gt;

&lt;p&gt;簡単のために，&lt;script type=&quot;math/tex&quot;&gt;\mathcal{X}=\mathbb{R}^d, \ \mathcal{Y}=\{1,\ldots,c\}&lt;/script&gt;とする． 今回は，「文書は単語の線形結合で表される」という仮定を置いてみる．つまり， &lt;script type=&quot;math/tex&quot;&gt;d=\sum_{i=1}^{n_w} \alpha^{(d)}_i w_i, \ \alpha^{(d)}_i \in \mathbb{R} \ \forall_i=1,\ldots,n_w&lt;/script&gt;  となる．さらに，「&lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt;は線形写像である」という仮定を置くと，
 &lt;script type=&quot;math/tex&quot;&gt;\phi(d)=\sum_{i=1}^{n_w} \alpha^{(d)}_i \phi(w_i)&lt;/script&gt;
 となる．というわけで，&lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt;ではなくて，コーパスから&lt;script type=&quot;math/tex&quot;&gt;\{\phi(w_i)\}_{i=1}^{n_w}&lt;/script&gt;を学習することにする．&lt;/p&gt;

&lt;p&gt;さて，やらなければならないのは，&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;コーパスから&lt;script type=&quot;math/tex&quot;&gt;\{\phi(w_i)\}_{i=1}^{n_w}&lt;/script&gt;を学習する&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;の決定&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;である．だいぶシンプルになったな．1に関しては死ぬほど研究されているので，その中から適用な手法を使うことにする． ここでは，PPMIを使って単語ベクトルを決定してみる．この辺は特に珍しくもないので，例えば以下を参照してください．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cl.ecei.tohoku.ac.jp/nlp100/&quot; title=&quot;http://www.cl.ecei.tohoku.ac.jp/nlp100/&quot;&gt;http://www.cl.ecei.tohoku.ac.jp/nlp100/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;残る問題は２だ．とりあえずシンプルさを追求して，単語の出現回数を使うことにする．つまり，&lt;script type=&quot;math/tex&quot;&gt;\alpha^{(d)}_i=c(w_i,d)&lt;/script&gt;とする． ただし，&lt;script type=&quot;math/tex&quot;&gt;c(w_i,d)&lt;/script&gt;は，文書&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;における単語&lt;script type=&quot;math/tex&quot;&gt;w_i&lt;/script&gt;の出現回数である． これで全ての問題が一応解決した．さあ，あとは実装するだけ．&lt;/p&gt;

&lt;div id=&quot;outline-container-sec-3&quot; class=&quot;outline-2&quot;&gt;
&lt;h2 id=&quot;sec-3&quot;&gt;実装&lt;/h2&gt;
&lt;div class=&quot;outline-text-2&quot; id=&quot;text-3&quot;&gt;
 コードは後日載せます． やっていることは，PPMIを要素とした単語-文脈行列を作り，その各行を単語ベクトルとします． あとは↑の定式化通りに文書ベクトルを生成し，文書分類器を作ります． その後，単語ベクトルたちを分類器にかけます． 文書分類器には，ロジスティック回帰（sklearn.linear_model.LogisticRegressionCV）を用います． デフォルト設定です（アプローチの可能性を見たいだけなので）． 
&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;sec-4&quot;&gt;実験&lt;/h2&gt;
&lt;p&gt;データはnaverまとめからクロールしたものを使う． カテゴリとそれに対応するクロールした文書数を以下の表に示す． これが今回の訓練データ．&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;カテゴリ&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;文書数&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ガールズ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;600&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ニュース・ゴシップ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;976&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;エンタメ・カルチャー&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;480&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;おでかけ・グルメ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;867&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;暮らし・アイデア&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;737&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;レシピ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;702&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;カラダ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;708&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ビジネススキル&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;558&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;IT・ガジェット&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;231&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;デザイン・アート&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;479&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;雑学&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;667&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;おもしろ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;584&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;定番&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;257&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;総異なり語数は14767件で，これが今回の分類対象となる． さて，結果はただ単語を羅列してもおもしろくないので，wordcloudを使おうと思う． これについては以下を参考にしました，ありがとうございます．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://qiita.com/kenmatsu4/items/9b6ac74f831443d29074&quot; title=&quot;http://qiita.com/kenmatsu4/items/9b6ac74f831443d29074&quot;&gt;http://qiita.com/kenmatsu4/items/9b6ac74f831443d29074&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;outline-container-sec-4-1&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-1&quot;&gt;ガールズ&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-1&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-girls.png&quot; alt=&quot;girls.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-2&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-2&quot;&gt;ニュース・ゴシップ&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-2&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-news.png&quot; alt=&quot;news.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-3&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-3&quot;&gt;エンタメ・カルチャー&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-3&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-entertainment.png&quot; alt=&quot;entertainment.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-4&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-4&quot;&gt;おでかけ・グルメ&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-4&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-spot.png&quot; alt=&quot;spot.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-5&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-5&quot;&gt;暮らし・アイデア&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-5&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-life.png&quot; alt=&quot;life.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-6&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-6&quot;&gt;レシピ&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-6&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-recipe.png&quot; alt=&quot;recipe.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-7&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-7&quot;&gt;カラダ&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-7&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-wellness.png&quot; alt=&quot;wellness.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-8&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-8&quot;&gt;ビジネススキル&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-8&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-business.png&quot; alt=&quot;business.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-9&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-9&quot;&gt;IT・ガジェット&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-9&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-tech.png&quot; alt=&quot;tech.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-10&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-10&quot;&gt;デザイン・アート&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-10&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-design.png&quot; alt=&quot;design.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-11&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-11&quot;&gt;雑学&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-11&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-trivia.png&quot; alt=&quot;trivia.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-12&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-12&quot;&gt;おもしろ&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-12&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-humor.png&quot; alt=&quot;humor.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-13&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-13&quot;&gt;定番&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-13&quot;&gt;
 該当単語なし 
&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;sec-5&quot;&gt;おわりに&lt;/h2&gt;
&lt;p&gt;今回はラベル付き文書データから文書分類器を学習し，それを単語分類に使用してみた． 結果は定性的に測るしかないが，うまくいっているところはあるのでアプローチは悪くないのかなと思う． 定番に該当がないのは定番だからなのだろうか？笑 ただ，もっと分類器をチューニングしたほうが良い気がする． いまはただロジスティック回帰にぶん投げているだけなので．&lt;/p&gt;

&lt;p&gt;次回は，教師あり次元削減，具体的にはFisher Discriminant Analysis (FDA)をかけてみます． いまは生の単語-文脈行列を使っているので，情報をもっと圧縮させて次元を削減しようと思います． さらに，教師ありデータを使うことで，同じラベルを持つものは近くなり，異なるラベルを持つものは遠くなるよう次元削減後の空間を学習します（正確には射影行列）． まぁとりあえずいいんではなかろうか．&lt;/p&gt;

</description>
        <pubDate>Tue, 29 Sep 2015 20:33:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/machine%20learning/2015/09/29/29203300.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/machine%20learning/2015/09/29/29203300.html</guid>
        
        <category>Machine Learning</category>
        
        <category>python</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
  </channel>
</rss>
