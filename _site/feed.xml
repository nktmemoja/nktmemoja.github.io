<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nktmemo_ja</title>
    <description>nktmemo provides interesting articles about Machine Learning and NLP. 
</description>
    <link>http://nktmemoja.github.io/</link>
    <atom:link href="http://nktmemoja.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 11 Jan 2016 12:54:29 +0900</pubDate>
    <lastBuildDate>Mon, 11 Jan 2016 12:54:29 +0900</lastBuildDate>
    <generator>Jekyll v3.0.0</generator>
    
      <item>
        <title>ソフトマージンSVMのヒンジ損失最小化学習としての解釈とその実装</title>
        <description>&lt;p&gt;前回，&lt;a href=&quot;http://nktmemoja.github.io/jekyll/update/2016/01/07/hardmarginsvmformulation.html&quot;&gt;ハードマージンSVMの定式化&lt;/a&gt;について書いたので，
今回はソフトマージンSVMの定式化をしようと思います．
さらに，それをヒンジ損失最小化学習として解釈できることを示し，
最後に確率的勾配法を使って実装したいと思います．&lt;/p&gt;

&lt;p&gt;さて，ハードマージンSVMの最適化問題は以下で与えられます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\min_{\boldsymbol{w},b} &amp;\ \|\boldsymbol{w}\|^2 \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1 \ \forall i=1,\ldots,n
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;しかし，与えられたデータに対して，この制約を満たす超平面が存在しない場合，実行可能領域が空集合となり，この最適化問題が解を持たなくなってしまいます．
そこで，制約を緩和するために，全てのサンプルに対して&lt;script type=&quot;math/tex&quot;&gt;\xi_i \geq 0&lt;/script&gt;を導入し，最適化問題を以下のように書き換えます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\min_{\boldsymbol{w},b,\{\xi_i\}_{i=1}^n} &amp;\ \|\boldsymbol{w}\|^2 + C \sum_{i=1}^n \xi_i\\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1-\xi_i \ \forall i=1,\ldots,n\\
&amp;\ \xi_i \geq 0 \ \forall i=1,\ldots,n
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;これは，訓練データでの誤識別をある程度許容することに相当します．
我々のゴールは汎化能力の獲得，つまり，未知のデータに対する誤識別率を最小化することなので，訓練データを全て正しく識別する必要はありません．
さらに，訓練データに完全にフィットさせることは，汎化能力の低下を引き起こす原因にもなります．そのような意味でも，制約の緩和は有用です．&lt;/p&gt;

&lt;p&gt;この最適化問題では，&lt;script type=&quot;math/tex&quot;&gt;\xi_i&gt;0&lt;/script&gt;の時，&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x}_i&lt;/script&gt;の誤識別を許容します．
さらに，&lt;script type=&quot;math/tex&quot;&gt;\xi_i&lt;/script&gt;は小さい方が望ましいので，目的関数に加えて同時に最小化します．
&lt;script type=&quot;math/tex&quot;&gt;C&lt;/script&gt;は識別率をコントロールするハイパーパラメータです．&lt;/p&gt;

&lt;p&gt;さて，ここで，&lt;script type=&quot;math/tex&quot;&gt;\xi_i&lt;/script&gt;を以下のように定義すると，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\xi_i = \max\{0,1-y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b)\}
\end{align*},&lt;/script&gt;

&lt;p&gt;上の最適化問題は，以下のように書き換えられます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\min_{\boldsymbol{w},b} \ \sum_{i=1}^n \max\{0,1-y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b)\} + \lambda \|\boldsymbol{w}\|^2
\end{align*}&lt;/script&gt;

&lt;p&gt;ここで，&lt;script type=&quot;math/tex&quot;&gt;\max\{0,1-y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b)\}&lt;/script&gt;を損失関数とみると，経験リスク最小化学習になっていることがわかります．損失関数&lt;script type=&quot;math/tex&quot;&gt;\ell_{hinge}(t) = \max\{0,1-t\}&lt;/script&gt;はヒンジ損失と呼ばれています．&lt;/p&gt;

&lt;p&gt;ここから実装について，書きたいと思います．
&lt;a rel=&quot;nofollow&quot; href=&quot;http://www.amazon.co.jp/gp/product/406152903X/ref=as_li_ss_tl?ie=UTF8&amp;amp;camp=247&amp;amp;creative=7399&amp;amp;creativeASIN=406152903X&amp;amp;linkCode=as2&amp;amp;tag=nettodesyuu00-22&quot; target=&quot;_blank&quot;&gt;オンライン機械学習 (機械学習プロフェッショナルシリーズ)&lt;/a&gt;&lt;img src=&quot;http://ir-jp.amazon-adsystem.com/e/ir?t=nettodesyuu00-22&amp;amp;l=as2&amp;amp;o=9&amp;amp;a=406152903X&quot; width=&quot;1&quot; height=&quot;1&quot; border=&quot;0&quot; alt=&quot;&quot; style=&quot;border:none !important; margin:0px !important;&quot; /&gt;を参考にしています．
SVMは二次計画法で解くこともできますが，今回は確率的勾配法（正確にはIncremental Gradient Method）を使って解きたいと思います．
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x} \in \mathbb{R}^{d+1}&lt;/script&gt; として，簡単のために &lt;script type=&quot;math/tex&quot;&gt;x_1 = 1&lt;/script&gt;とします．すると，切片&lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;が&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}&lt;/script&gt;に吸収され，上の最適化問題は，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\min_{\boldsymbol{w},b} \ \sum_{i=1}^n \max\{0,1-y_i\boldsymbol{w}^T \boldsymbol{x}_i\} + \lambda \|\boldsymbol{w}\|^2
\end{align*}&lt;/script&gt;

&lt;p&gt;と書けます．
確率的勾配法では，適当にサンプル&lt;script type=&quot;math/tex&quot;&gt;(\boldsymbol{x}_i,y_i)&lt;/script&gt;を一つ取り出して，それに対応する目的関数，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
J_i(\boldsymbol{w}) = \max\{0,1-y_i\boldsymbol{w}^T \boldsymbol{x}_i\} + \lambda \|\boldsymbol{w}\|^2
\end{align*},&lt;/script&gt;

&lt;p&gt;の勾配を求めます．その勾配&lt;script type=&quot;math/tex&quot;&gt;\nabla J_i(\boldsymbol{w})&lt;/script&gt;を用いて，パラメータを&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w} \leftarrow \boldsymbol{w} - \eta\nabla J_i(\boldsymbol{w})&lt;/script&gt;と更新します．これを収束まで繰り返します．&lt;/p&gt;

&lt;p&gt;しかし，ヒンジ損失は&lt;script type=&quot;math/tex&quot;&gt;1-y_i\boldsymbol{w}^T \boldsymbol{x}_i = 0&lt;/script&gt;を満たす点で微分不可能なため，劣勾配を考えます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\nabla J_i(\boldsymbol{w}) = \left\{
\begin{array}{ll}
-y_i\boldsymbol{x}_i + 2 \lambda \boldsymbol{w} &amp; (1-y_i\boldsymbol{w}^T \boldsymbol{x}_i \geq 0) \\
2 \lambda \boldsymbol{w} &amp; otherwise
\end{array}\right.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;これを踏まえると，アルゴリズムは以下のようになります．&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ランダムに&lt;script type=&quot;math/tex&quot;&gt;(\boldsymbol{x}_i,y_i) \in \{(\boldsymbol{x}_i,y_i)\}_{i=1}^n&lt;/script&gt;を取り出す．&lt;/li&gt;
  &lt;li&gt;以下のように&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}&lt;/script&gt;を更新 (&lt;script type=&quot;math/tex&quot;&gt;\eta&lt;/script&gt;はステップサイズ)&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\boldsymbol{w} \leftarrow
\boldsymbol{w} - \eta\left(2 \lambda \boldsymbol{w} + 
\left\{
\begin{array}{ll}
-y_i\boldsymbol{x}_i &amp; (1-y_i\boldsymbol{w}^T \boldsymbol{x}_i \geq 0) \\
0 &amp; otherwise
\end{array}\right.\right)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;実装してみました．
&lt;script src=&quot;https://gist.github.com/nktmemoja/15c7120a873f6195ee86.js&quot;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;結果は以下のようになりました．
&lt;img src=&quot;/assets/softmarginsvm_demo.png&quot; alt=&quot;softmarginsvm_demo.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;なお，以下に書いたように，実装においてはステップサイズの決定が非常に難しいです．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;[http://nktmemoja.github.io/jekyll/update/2016/01/10/gradient-method.html]&quot;&gt;勾配法で目的関数値は単調に減少していくのか？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;実際に使用する時は，scikit-learnのsklearn.linear_model.SGDClassifierを使うのが賢明でしょう．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html&quot; target=&quot;_blank&quot;&gt;http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今回はソフトマージンSVMを定式化し，確率的勾配法を用いて実装してみた．
とりあえず簡単な人工データでうまく動くことを確認した．
この実装は実用に耐えうるものではないので，簡単なデモだと思ってください^^．
読んでいただき，ありがとうございました．&lt;/p&gt;

</description>
        <pubDate>Mon, 11 Jan 2016 12:43:59 +0900</pubDate>
        <link>http://nktmemoja.github.io/jekyll/update/2016/01/11/softmarginsvm.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/jekyll/update/2016/01/11/softmarginsvm.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>勾配法で目的関数値は単調に減少していくのか？</title>
        <description>&lt;p&gt;目的関数&lt;script type=&quot;math/tex&quot;&gt;f: \mathbb{R}^d \rightarrow \mathbb{R}&lt;/script&gt;の最小化を考えましょう．
勾配法では，以下のようにパラメータ&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x}&lt;/script&gt;を更新していきます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\boldsymbol{x}_{k+1} = x_k - h_k \nabla f(\boldsymbol{x}_k), \ k=0,1,\ldots
\end{align*}&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;h_k &gt; 0&lt;/script&gt;はステップサイズ．&lt;/p&gt;

&lt;p&gt;1ステップ分の更新を考えましょう．
&lt;script type=&quot;math/tex&quot;&gt;y = \boldsymbol{x} - h_k \nabla f(\boldsymbol{x})&lt;/script&gt;とすると，我々が示したいのは，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
f(\boldsymbol{y}) \leq f(\boldsymbol{x})
\end{align*}.&lt;/script&gt;

&lt;p&gt;これだけではなにも議論できないので，これからは目的関数はリプシッツ連続 (Lipschitz continuous) だとします．
ではまずリプシッツ連続の定義から始めましょう．&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;Q \subseteq \mathbb{R}^d, L&gt;0&lt;/script&gt;に対して，集合&lt;script type=&quot;math/tex&quot;&gt;C^{k,p}_L(Q)&lt;/script&gt;を以下の性質を有する集合とします．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f \in C^{k,p}_L(Q)&lt;/script&gt; はk回微分可能で連続&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f^{(p)}&lt;/script&gt;を&lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;のp階微分とすると，
&lt;script type=&quot;math/tex&quot;&gt;\|f^{(p)}(\boldsymbol{x}) - f^{(p)}(\boldsymbol{y})\|_2 \leq L\|\boldsymbol{x}-\boldsymbol{y}\|_2 \ \forall \boldsymbol{x},\boldsymbol{y} \in Q&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;この時&lt;script type=&quot;math/tex&quot;&gt;f\in C^{k,p}_L(Q)&lt;/script&gt;はリプシッツ連続であるという．&lt;/p&gt;

&lt;p&gt;今，目的関数が&lt;script type=&quot;math/tex&quot;&gt;f \in C^{1,1}_L(\mathbb{R}^d)&lt;/script&gt;だとしましょう．この時，以下が成立します．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
|f(\boldsymbol{y})-f(\boldsymbol{x})-\langle f&#39;(\boldsymbol{x}),\boldsymbol{y}-\boldsymbol{x} \rangle| \leq \frac{L}{2}\|\boldsymbol{y}-\boldsymbol{x}\|_2^2 \ \cdots (1)
\end{align*}&lt;/script&gt;

&lt;p&gt;さて，再び勾配法による一回分の更新を考えましょう．
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{y}=\boldsymbol{x}-h\nabla f(\boldsymbol{x})&lt;/script&gt;とすると，(1)より，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
f(\boldsymbol{y}) &amp;\leq f(\boldsymbol{x}) + \langle \nabla f(\boldsymbol{x}), \boldsymbol{y}-\boldsymbol{x} \rangle + \frac{L}{2}\|\boldsymbol{y}-\boldsymbol{x}\|^2_2 \\
&amp;= f(\boldsymbol{x}) - h\left(1 - \frac{h}{2}L\right)\|\nabla f(\boldsymbol{x})\|^2_2
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;したがって，&lt;script type=&quot;math/tex&quot;&gt;h\left(1 - \frac{h}{2}L\right) \geq 0&lt;/script&gt;，つまり，&lt;script type=&quot;math/tex&quot;&gt;h \leq \frac{2}{L}&lt;/script&gt;であれば，&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{y}) \leq f(\boldsymbol{x})&lt;/script&gt;が言えます．
つまり，当たり前かもしれませんが，勾配法によって関数が単調に減少するかはステップサイズの決め方に依存するということです．
ここから，ステップサイズの決め方がいかに重要かがわかりますね．&lt;/p&gt;

&lt;p&gt;問題なのは&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;がわからないということです．
もっともナイーブなステップサイズの決定方法は&lt;script type=&quot;math/tex&quot;&gt;h_k = h \ \forall k=0,1,\ldots&lt;/script&gt;として，適当に&lt;script type=&quot;math/tex&quot;&gt;h&gt;0&lt;/script&gt;を決めてやることですが，これだと必ずしも&lt;script type=&quot;math/tex&quot;&gt;h \leq \frac{2}{L}&lt;/script&gt;となっている保証はありません．そこで，なんらかの工夫が必要です．&lt;/p&gt;

&lt;p&gt;基本的には，更新の際に，&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{y}) \leq f(\boldsymbol{x})&lt;/script&gt;となる&lt;script type=&quot;math/tex&quot;&gt;h&gt;0&lt;/script&gt;を選べば良いわけですが，どうやったら良いのでしょうか？
適当に&lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt;を決めましょう．この時，&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{y}) &gt; f(\boldsymbol{x})&lt;/script&gt;となってしまったとします．
この時の戦略は，&lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt;を大きくするか，小さくするかです．どうしたらいいでしょう？&lt;/p&gt;

&lt;p&gt;もしも，更新によって関数値が増加してしまう時，つまり&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{y})&gt;f(\boldsymbol{x})&lt;/script&gt;の時，ステップサイズが&lt;script type=&quot;math/tex&quot;&gt;h&gt;\frac{2}{L}&lt;/script&gt;となっていることがわかります．ここから，&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{y}) \leq f(\boldsymbol{x})&lt;/script&gt;となるまで&lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt;を小さくしていけば良いことがわかります．
これは，更新によって，局所解または最適解を通り過ぎてしまったので，通り過ぎない程度に引き戻すことに相当します．
こんな感じでステップサイズを決めれば，一応目的関数は単調に減少していきます．&lt;/p&gt;

&lt;p&gt;まとめると，勾配法を使う際に最低限考えなければならないことは，&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{x}_{k+1}) \leq f(\boldsymbol{x}_k)&lt;/script&gt;となるように更新することで，これはステップサイズの決定に委ねられる．ステップサイズは，&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{x}_{k+1}) \leq f(\boldsymbol{x}_k)&lt;/script&gt;を満たすように決めれば良いが，もしこれが満たされない場合はステップサイズを小さくしていけば良い．&lt;/p&gt;

&lt;p&gt;こんな感じですかね．実際は，ステップサイズの決め方にもGoldstein-Armijo ruleとか，いろいろあるのでそれを使えばいいんですけどね．&lt;/p&gt;
</description>
        <pubDate>Mon, 11 Jan 2016 06:20:07 +0900</pubDate>
        <link>http://nktmemoja.github.io/jekyll/update/2016/01/11/gradient-method.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/jekyll/update/2016/01/11/gradient-method.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>ハードマージンSupport Vector Machine (SVM)の定式化</title>
        <description>&lt;p&gt;&lt;a rel=&quot;nofollow&quot; href=&quot;http://www.amazon.co.jp/gp/product/4061529064/ref=as_li_ss_tl?ie=UTF8&amp;amp;camp=247&amp;amp;creative=7399&amp;amp;creativeASIN=4061529064&amp;amp;linkCode=as2&amp;amp;tag=nettodesyuu00-22&quot; target=&quot;_blank&quot;&gt;サポートベクトルマシン (機械学習プロフェッショナルシリーズ)&lt;/a&gt;&lt;img src=&quot;http://ir-jp.amazon-adsystem.com/e/ir?t=nettodesyuu00-22&amp;amp;l=as2&amp;amp;o=9&amp;amp;a=4061529064&quot; width=&quot;1&quot; height=&quot;1&quot; border=&quot;0&quot; alt=&quot;&quot; style=&quot;border:none !important; margin:0px !important;&quot; /&gt;
を読んでいます．
SVMについて，わかっている気になっていましたが，わかっていませんでした．
意外と奥が深いですね．というわけでその整理の意味も込めてのポスト．&lt;/p&gt;

&lt;p&gt;この記事ではハードマージンSVMを考えます．
ハードマージンSVMでは，与えられたデータは線形分離可能であると仮定します．
つまり，超平面&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{x})=\boldsymbol{w}^T \boldsymbol{x} + b&lt;/script&gt;で，与えられた訓練データがミスなく分離できることを仮定します．
このような超平面は複数存在すると考えられますが，
SVMでは，「マージンを最大化する超平面を求める」，というのはよくある説明ですね．&lt;/p&gt;

&lt;p&gt;ではまず，マージンの定義から入りましょう．
今，訓練データ&lt;script type=&quot;math/tex&quot;&gt;\{(\boldsymbol{x}_i,y_i)\}_{i=1}^n, \boldsymbol{x}_i \in \mathbb{R}^d, y_i \in \{-1,1\} \ \forall i=1, \ldots, n&lt;/script&gt;が与えられているとします．
マージンを，
超平面&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{x})=\boldsymbol{w}^T \boldsymbol{x} + b&lt;/script&gt;からもっとも近いサンプルまでの距離と定義します．
つまり，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
i^{*} = \mathop{\rm arg\,min}\limits_{1 \leq i \leq n} \ \frac{|\boldsymbol{w}^T \boldsymbol{x}_i + b|}{\|\boldsymbol{w}\|}
= \mathop{\rm arg\,min}\limits_{1 \leq i \leq n} \ |\boldsymbol{w}^T \boldsymbol{x}_i + b|
\end{align*}&lt;/script&gt;

&lt;p&gt;と定義すると，マージンは&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\frac{|\boldsymbol{w}^T \boldsymbol{x}_{i^{*}} + b|}{\|\boldsymbol{w}\|}
\end{align*}&lt;/script&gt;

&lt;p&gt;と表すことができます．
全ての訓練データを正しく分類しつつ，このマージンを最大化したいので，以下の最適化問題を解きます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\max_{\boldsymbol{w},b} &amp;\ \frac{|\boldsymbol{w}^T \boldsymbol{x}_{i^{*}} + b|}{\|\boldsymbol{w}\|} \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) &gt; 0 \ \forall i=1,\ldots ,n
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;分子が邪魔なので，これを以下のように書き換えます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\max_{\boldsymbol{w},b} &amp;\ \frac{1}{\|\boldsymbol{w}\|} \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) &gt; 0 \ \forall i=1,\ldots ,n \\
&amp;\ |\boldsymbol{w}^T \boldsymbol{x}_{i^{*}} + b |=1
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;二つの制約条件を一つにまとめると，以下のようになります．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\max_{\boldsymbol{w},b} &amp;\ \frac{1}{\|\boldsymbol{w}\|} \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1 \ \forall i=1,\ldots ,n \\
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;個人的にはここの変形が一番きつかったですね…．
なので軽く補足しときます．
以下の制約を書き換えていきます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
 y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) &gt; 0 \ \forall i=1,\ldots ,n \ \cdots (1) \\
 |\boldsymbol{w}^T \boldsymbol{x}_{i^{*}} + b |=1 \ \cdots (2)
\end{align}&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;i^{*}&lt;/script&gt;の定義から，(2)は以下のように書き換えられます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\ |\boldsymbol{w}^T \boldsymbol{x}_{i} + b| \geq 1  \ \forall i=1,\ldots ,n \ \cdots (2&#39;)
\end{align}&lt;/script&gt;

&lt;p&gt;ここで，(1)と(2’)を合体させたいのですが，
&lt;script type=&quot;math/tex&quot;&gt;y_i(\boldsymbol{w}^T \boldsymbol{x}_{i} + b) = |\boldsymbol{w}^T \boldsymbol{x}_{i} + b|&lt;/script&gt;
を示すことができれば良さそうです．
ここで，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) = \left\{
\begin{array}
\boldsymbol{w}^T \boldsymbol{x}_i + b &amp; (y_i=1) \\
-(\boldsymbol{w}^T \boldsymbol{x}_i + b) &amp; (y_i=-1)
\end{array}
\right.
\end{align*}, %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
|\boldsymbol{w}^T \boldsymbol{x}_i + b| = \left\{
\begin{array}
\boldsymbol{w}^T \boldsymbol{x}_i + b &amp; (\boldsymbol{w}^T \boldsymbol{x}_i + b \geq 0) \\
-(\boldsymbol{w}^T \boldsymbol{x}_i + b) &amp; (\boldsymbol{w}^T \boldsymbol{x}_i + b &lt; 0)
\end{array}
\right.
\end{align*}, %]]&gt;&lt;/script&gt;

&lt;p&gt;ですが，(1)より，&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}^T \boldsymbol{x}_i + b \geq 0&lt;/script&gt; は成り立たず，この文脈では必ず
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}^T \boldsymbol{x}_i + b &gt; 0&lt;/script&gt;となります．&lt;/p&gt;

&lt;p&gt;なので，&lt;script type=&quot;math/tex&quot;&gt;y_i=1 \Leftrightarrow \boldsymbol{w}^T \boldsymbol{x}_i + b &gt; 0&lt;/script&gt;と
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
y_i=-1 \Leftrightarrow \boldsymbol{w}^T \boldsymbol{x}_i + b &lt; 0 %]]&gt;&lt;/script&gt;を示すことにします．
すごく簡単すぎて示す必要もないかもしれませんが…．&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;y_i=1&lt;/script&gt;の時，(1)より，&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}^T \boldsymbol{x}_i + b &gt; 0&lt;/script&gt;．
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}^T \boldsymbol{x}_i + b &gt; 0&lt;/script&gt;の時，(1)と&lt;script type=&quot;math/tex&quot;&gt;y_i \in \{-1,1\}&lt;/script&gt;より，&lt;script type=&quot;math/tex&quot;&gt;y_i=1&lt;/script&gt;．
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
y_i=-1 \Leftrightarrow \boldsymbol{w}^T \boldsymbol{x}_i + b &lt; 0 %]]&gt;&lt;/script&gt;も同様．&lt;/p&gt;

&lt;p&gt;よって，
&lt;script type=&quot;math/tex&quot;&gt;y_i(\boldsymbol{w}^T \boldsymbol{x}_{i} + b) = |\boldsymbol{w}^T \boldsymbol{x}_{i} + b|&lt;/script&gt;．&lt;/p&gt;

&lt;p&gt;そういうわけで，(2’)は，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\ y_i(\boldsymbol{w}^T \boldsymbol{x}_{i} + b) \geq 1  \ \forall i=1,\ldots ,n \ \cdots (2&#39;&#39;)
\end{align}&lt;/script&gt;

&lt;p&gt;これで，(1)と(2’‘)を合体できますね．
最後に最大化と最小化を書き換えて，ノルムを2乗すれば，よく見るハードマージンSVMの最適化問題の完成です：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\min_{\boldsymbol{w},b} &amp;\ \|\boldsymbol{w}\|^2 \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1 \ \forall i=1,\ldots ,n 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;ここで，与えられたデータに対して，制約&lt;script type=&quot;math/tex&quot;&gt;y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1 \ \forall i=1,\ldots ,n&lt;/script&gt;を満たす&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;が存在しないかもしれません．
というより，現実問題ではそのような場合がほとんどだと考えられます．
そこで，ソフトマージンの考え方が出てきます．
これについてはまた後日書けたらと思います．&lt;/p&gt;
</description>
        <pubDate>Fri, 08 Jan 2016 00:30:29 +0900</pubDate>
        <link>http://nktmemoja.github.io/jekyll/update/2016/01/08/hardmarginsvmformulation.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/jekyll/update/2016/01/08/hardmarginsvmformulation.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>正例とラベル無しデータからの学習 (PU classification)</title>
        <description>&lt;p&gt;通常の2値分類問題では，正例と負例が与えられています． しかし扱う問題によっては，このようなデータを用意するのが困難な時があります． 例えば，抽出型のタスクです． 抽出型のタスクでは，抽出したい対象を正例と考えます． この場合の負例は「正例以外のデータ」と定義するほかありません． しかし，集めた正例に対し，それ以外のデータを負例と定義してしまうと， それ以外のデータに含まれる正例も負例として扱ってしまいます．&lt;/p&gt;

&lt;p&gt;このように負例を定義するのが難しい場合には，正例とラベルなしデータから学習する枠組み，PU classificationが有用です． PU classificationについては，Elkan and Noto 2008を参照していただければと思うのですが，少しだけ解説しておきます． 3つの確率変数&lt;script type=&quot;math/tex&quot;&gt;x,y,s&lt;/script&gt;を考えます．ここで，&lt;script type=&quot;math/tex&quot;&gt;x \in \mathbb{R}, y \in \{-1,1\}, s \in \{0,1\}&lt;/script&gt;だとします． &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;は入力，&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;はクラスラベル，そして&lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt;はデータがラベリングされるかどうかを表しています． 我々が欲しいのは，
&lt;script type=&quot;math/tex&quot;&gt;p(y|x)&lt;/script&gt;
ですが，PU classificationでは&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;は観測することができません． 我々のゴールは，&lt;script type=&quot;math/tex&quot;&gt;\{(x_i,s_i)\}_{i=1}^n&lt;/script&gt;から
&lt;script type=&quot;math/tex&quot;&gt;p(y|x)&lt;/script&gt;
を学習することです． 結果からいうと，2つの仮定をおくことで，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y=1|x) = \frac{p(s=1|x)}{p(s=1|y=1)}&lt;/script&gt;

&lt;p&gt;と表せます．
&lt;script type=&quot;math/tex&quot;&gt;p(s=1|x)&lt;/script&gt;
は与えられたデータから推定できます． そして，
&lt;script type=&quot;math/tex&quot;&gt;p(s=1|y=1)&lt;/script&gt;
は開発データから推定できます． 詳しくはElkan and Noto 2008の2章にまとめられています． 今回はElkan and Noto 2008の手法を用いてPU classificationを行っていきます．&lt;/p&gt;

&lt;p&gt;では，以下のような正解データを考えましょう． &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-true_labeled.png&quot; alt=&quot;true_labeled.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;このデータに対して，実際に与えられるのは以下のようなデータです． &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-pu_data.png&quot; alt=&quot;pu_data.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;このデータに対して，まずは通常のロジスティック回帰を適用してみます． なお，今回は負例が多いので，交差確認法には正例側のF値を用います． 結果は以下のようになりました． &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-result_of_tradclf1.png&quot; alt=&quot;result_of_tradclf.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ご覧のように，全て負例だと予測してしまいました． 次に，PU classificationを適用してみます． &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-result_of_puclassification.png&quot; alt=&quot;result_of_puclassification.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;正例とラベルなしデータから，うまく分類境界を学習できていることがわかります．&lt;/p&gt;

&lt;p&gt;デモ用のコードは以下に載せておきますのでぜひ試してみてください． ちなみに，非線形な分類境界を表現するための&lt;a href=&quot;https://gist.github.com/nkt1546789/e41199340f7a42c515be&quot; title=&quot;rbfmodel_wrapper.py&quot;&gt;rbfmodel_wrapper.py&lt;/a&gt; と PU Classificationのための&lt;a href=&quot;https://gist.github.com/nkt1546789/9fbbf2f450779bde60c3&quot; title=&quot;puwrapper.py&quot;&gt;puwrapper.py&lt;/a&gt; も合わせてDLしてください．&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/nkt1546789/e9421f06ea3a62bfbb8c&quot; title=&quot;https://gist.github.com/nkt1546789/e9421f06ea3a62bfbb8c&quot;&gt;https://gist.github.com/nkt1546789/e9421f06ea3a62bfbb8c&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Thu, 29 Oct 2015 21:47:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/machine%20learning/2015/10/29/29214700.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/machine%20learning/2015/10/29/29214700.html</guid>
        
        <category>Machine Learning</category>
        
        <category>PU classification</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Word2Vecを使った単語間関係分類</title>
        <description>&lt;p&gt;単語間には様々な関係があります． 今回は，単語間の関係をWord2Vecで学習させようと思います． Word2Vecにはアナロジーを捉えられるという話があります． あの有名な，king - man + woman = queen というやつですね． これは，king - man = queen - womanとも書けます． つまり，2語間の差が関係を表しており， この例だと，kingとmanの関係とqueenとwomanの関係が同じであると捉えることができます．&lt;/p&gt;

&lt;p&gt;さて，Word2Vecで学習したベクトル表現を使うと，差ベクトルがうまいこと関係を表すと書きましたが， 必ずしもそうなっているとは限りません． 加えて，ユーザが扱いたい関係とWord2Vecで学習した関係が一致しているとも限りません． そこで，今回も例のごとく教師あり学習を使います． ユーザは教師データを通して，扱いたい関係をアルゴリズムに伝えることができます．&lt;/p&gt;

&lt;p&gt;最初からあまり多くの関係を対象にするのはしんどいので，今回はis-a, has-a関係のみに着目します． これは，僕の理解では，柔道 is-a スポーツ，スポーツ has-a 柔道みたいなものだと思っています． まずは&lt;a href=&quot;https://gist.github.com/nkt1546789/a3b3a4c166fc1c0486a1&quot; title=&quot;training data&quot;&gt;training data&lt;/a&gt;を用意します． is-aとhas-aは反対の関係になっていると思うので，has-aのデータだけ用意します． この中には (スポーツ，野球)というhas-a関係を表す順序対がリストで格納されています． リスト内の順序対に対して差ベクトルを計算し，一つのデータとして扱います．&lt;/p&gt;

&lt;p&gt;コードは以下のようになりました．&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;training&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;gensim.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LogisticRegressionCV&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;/path/to/your/w2v_model&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ntr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ntr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ntr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Xtr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ytr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Xte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;yte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogisticRegressionCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Xtr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ytr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ypred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Xte&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yte&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ypred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; 0.99502487562189057&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;今回は厳密な実験はせずに，簡単に性能を見てみました． テストデータに対して，99%の精度を出すことができました． 以下簡単なテストデータへの予測例です．&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ypred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;has-a&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;is-a&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# results:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;ブルーベリー&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;果物&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;動物&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;モルモット&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;動物&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;ワタボウシタマリン&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;登山&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;ロデオ&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;動物&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;ユーラシアカワウソ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;フリーダイビング&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;競馬&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;ゴルフ&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;いかがでしょうか？うまく狙った関係が分類できていると思います． とりあえずはうまくいきました！これで成功です！ これがどこまで実用に耐えられるかはやってみないとわかりませんが．&lt;/p&gt;

</description>
        <pubDate>Tue, 27 Oct 2015 20:57:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/machine%20learning/2015/10/27/27205700.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/machine%20learning/2015/10/27/27205700.html</guid>
        
        <category>Machine Learning</category>
        
        <category>NLP</category>
        
        <category>python</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Word2Vec+教師あり次元削減で文書分類+単語分類</title>
        <description>&lt;p&gt;前回:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://nktmemo.wordpress.com/2015/09/29/%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E5%99%A8%E3%81%A7%E5%8D%98%E8%AA%9E%E5%88%86%E9%A1%9E%E3%82%92%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B/&quot; title=&quot;https://nktmemo.wordpress.com/2015/09/29/%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E5%99%A8%E3%81%A7%E5%8D%98%E8%AA%9E%E5%88%86%E9%A1%9E%E3%82%92%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B/&quot;&gt;文書分類器で単語分類をしてみる&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の続きです．&lt;/p&gt;

&lt;p&gt;まずは，前回のおさらい． 前回は，文書に対してはラベル付きデータが与えられており，単語についてはラベルなしデータが与えられているという設定を考えました． そして，文書と単語が同じ空間に存在すれば，半教師付き学習に帰着することを示しました． 詳しくは前回の記事を見ていただくとして，これからは半教師付き学習の設定で話を進めます．&lt;/p&gt;

&lt;p&gt;今回は，前回の記事でいう単語ベクトル集合&lt;script type=&quot;math/tex&quot;&gt;\{x_i\}_{i=n_d}^{n}&lt;/script&gt;をWord2Vecで学習させます． 食わせるコーパスは分類対象の文書集合です．&lt;/p&gt;

&lt;p&gt;その後，教師あり次元削減手法であるFisher Discriminant Analysis (FDA)を使って&lt;script type=&quot;math/tex&quot;&gt;B:\mathbb{R}^d\rightarrow\mathbb{R}^m&lt;/script&gt;を学習させます． これによって，Word2Vecで学習した単語ベクトルたちは，より低次元の空間に落とし込まれます． つまり，&lt;script type=&quot;math/tex&quot;&gt;z=Bx&lt;/script&gt;として，&lt;script type=&quot;math/tex&quot;&gt;\{(z_i,y_i)\}_{i=1}^{n_d}&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;\{z_i\}_{i=n_d}^{n}&lt;/script&gt;を得ます． 今回は，&lt;script type=&quot;math/tex&quot;&gt;m=c-1&lt;/script&gt;としました，ただし，&lt;script type=&quot;math/tex&quot;&gt;c&lt;/script&gt;はクラス数です．&lt;/p&gt;

&lt;p&gt;なぜこのような処理をするかというと，Word2Vecのような教師なし学習では，必ずしも「望ましい結果」が得られるとは限りません． なぜなら，「望ましい結果」についての情報を一切与えていないからです． 今回の目的は文書分類+単語分類です． この目的に対して，Word2Vecが必ずしも望ましい結果を返すとは限らないのです．&lt;/p&gt;

&lt;p&gt;そこで，教師あり次元削減を使います． FDAは，簡単にいうと，同じクラスに属するサンプルは近く，異なるクラスに属するサンプルは遠くなるよう，射影行列を学習します． ここでは，「望ましい結果」教師データとして与えるので，学習後の空間は分類という目的に対して望ましい空間になっていると期待できます．&lt;/p&gt;

&lt;p&gt;さて，あとは対して面白いことはしていません． &lt;script type=&quot;math/tex&quot;&gt;\{(z_i,y_i)\}_{i=1}^{n_d}&lt;/script&gt;で確率的分類器を学習させ，&lt;script type=&quot;math/tex&quot;&gt;\{z_i\}_{i=n_d}^{n}&lt;/script&gt;に対して予測をします．&lt;/p&gt;

&lt;p&gt;前回と同じデータを使って実験をしました． 結果の出力には同様にwordcloudを使わせてもらいました．&lt;/p&gt;

&lt;p&gt;ガールズ: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-girls.png&quot; alt=&quot;girls.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ニュース・ゴシップ: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-news1.png&quot; alt=&quot;news.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;エンタメ・カルチャー: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-entertainment1.png&quot; alt=&quot;entertainment.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;おでかけ・グルメ: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-spot1.png&quot; alt=&quot;spot.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;暮らし・アイデア: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-life1.png&quot; alt=&quot;life.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;レシピ: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-recipe1.png&quot; alt=&quot;recipe.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;カラダ: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-wellness1.png&quot; alt=&quot;wellness.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ビジネススキル: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-business1.png&quot; alt=&quot;business.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;IT・ガジェット: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-tech1.png&quot; alt=&quot;tech.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;デザイン・アート: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-design1.png&quot; alt=&quot;design.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;雑学: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-trivia1.png&quot; alt=&quot;trivia.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;おもしろ: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-humor1.png&quot; alt=&quot;humor.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;定番: &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-popular1.png&quot; alt=&quot;popular.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;評価データがなくて定性的に評価するしかないのですが，前回と比べて，かなり改善されている気がします． 雑学とかおもしろ，定番なんかは定義がよくわからなくて判断しにくいですが，それ以外はうまく単語分類ができていると思います．&lt;/p&gt;

&lt;p&gt;今回は，Word2Vec+教師あり次元削減 (FDA) を使って文書分類器を作成し，それを使って単語分類をしてみました． 結果として，このアプローチはなかなか良いと感じました． 文書分類，単語分類については，これでひと段落した感じがします． 本当は単語分類なんかはマルチラベル分類問題として解くべくなのかもしれませんが，あまりこの問題に執着してもあれなので． 次は要約や，トレンド抽出なんかをやっていきたいなあなんて思っています．&lt;/p&gt;

&lt;p&gt;前回と今回はコードを載せていません． これはコードがなかなか複雑なためです． もし，見てみたいという方がいたら，コメントからでも，Twitterからでもなんでも良いので言ってください！ 読んでいただき，ありがとうございました．&lt;/p&gt;

</description>
        <pubDate>Tue, 06 Oct 2015 20:46:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/machine%20learning/2015/10/06/06204600.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/machine%20learning/2015/10/06/06204600.html</guid>
        
        <category>Machine Learning</category>
        
        <category>NLP</category>
        
        <category>python</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>文書分類器で単語分類をしてみる</title>
        <description>&lt;p&gt;keywords: 文書分類 (document classification）， 単語分類（word classification）， Pointwise mutual information&lt;/p&gt;

&lt;h2 id=&quot;sec-1&quot;&gt;はじめに&lt;/h2&gt;
&lt;p&gt;文書へのラベリングと単語へのラベリングはどちらが簡単だろう？ 例えば多くのニュースサイトではすでに文書は分類されている． しかし，単語が分類されているのは見たことがない． というより，そんなものを表に出してもあまり意味がないので表に出ていないのだろう． この状況を踏まえると，データをクロールする側からすると，ラベル付き文書データを入手するのは容易で， ラベル付き単語データを入手するのは困難だと言える．&lt;/p&gt;

&lt;p&gt;いま，文書データをクロールして，検索エンジンを作ることを考えよう． 各文書にはラベルが付いている． このラベル情報を活かせないか？ 例えばクエリにラベルが付いていれば，クエリと文書のラベルを見て，一致するものを出せばよい，あるいはそういう場合にスコアが高くなるように，検索エンジンのスコアを設計すれば良い． このように，単語へのラベリングはある程度需要があると推測される．&lt;/p&gt;

&lt;h2 id=&quot;sec-2&quot;&gt;定式化&lt;/h2&gt;

&lt;p&gt;さて，今回やるのは，ラベル付き文書データを使って，単語分類をしようというもの． つまり，持っているものは，&lt;script type=&quot;math/tex&quot;&gt;\{(d_i,y_i)\}_{i=1}^{n_d}&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;\{w_i\}_{i=1}^{n_w}&lt;/script&gt;， ただし，&lt;script type=&quot;math/tex&quot;&gt;d_i \in \mathcal{D}&lt;/script&gt;は文書，&lt;script type=&quot;math/tex&quot;&gt;y_i \in \mathcal{Y}&lt;/script&gt;は文書に対するラベル, &lt;script type=&quot;math/tex&quot;&gt;w_i \in \mathcal{W}&lt;/script&gt;は単語を意味する．&lt;/p&gt;

&lt;p&gt;ここで，もし単語と文書が同じ空間に存在すれば，文書分類器を使って単語分類ができると思われる． つまり，&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}=\mathcal{D}=\mathcal{W}&lt;/script&gt;とし，なんらかの変換&lt;script type=&quot;math/tex&quot;&gt;\phi:\mathcal{S} \rightarrow \mathcal{X}&lt;/script&gt;を定義すればよい． ここまで来れば，&lt;script type=&quot;math/tex&quot;&gt;x_i=\phi(d_i) \ \forall i=1,\ldots,n_d, \ x_{n_w+j}=\phi(w_j) \ \forall j=1,\ldots,n_w&lt;/script&gt;とし， &lt;script type=&quot;math/tex&quot;&gt;\{(x_i,y_i)\}_{i=1}^{n_d}&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;\{x_i\}_{i=n_d}^{n}&lt;/script&gt;を得る．ただし&lt;script type=&quot;math/tex&quot;&gt;n=n_d+n_w&lt;/script&gt;． こうして見てみると，単語と文書を同じ空間に写像すれば，これは半教師付き分類問題に帰着することがわかる．&lt;/p&gt;

&lt;p&gt;簡単のために，&lt;script type=&quot;math/tex&quot;&gt;\mathcal{X}=\mathbb{R}^d, \ \mathcal{Y}=\{1,\ldots,c\}&lt;/script&gt;とする． 今回は，「文書は単語の線形結合で表される」という仮定を置いてみる．つまり， &lt;script type=&quot;math/tex&quot;&gt;d=\sum_{i=1}^{n_w} \alpha^{(d)}_i w_i, \ \alpha^{(d)}_i \in \mathbb{R} \ \forall_i=1,\ldots,n_w&lt;/script&gt;  となる．さらに，「&lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt;は線形写像である」という仮定を置くと，
 &lt;script type=&quot;math/tex&quot;&gt;\phi(d)=\sum_{i=1}^{n_w} \alpha^{(d)}_i \phi(w_i)&lt;/script&gt;
 となる．というわけで，&lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt;ではなくて，コーパスから&lt;script type=&quot;math/tex&quot;&gt;\{\phi(w_i)\}_{i=1}^{n_w}&lt;/script&gt;を学習することにする．&lt;/p&gt;

&lt;p&gt;さて，やらなければならないのは，&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;コーパスから&lt;script type=&quot;math/tex&quot;&gt;\{\phi(w_i)\}_{i=1}^{n_w}&lt;/script&gt;を学習する&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;の決定&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;である．だいぶシンプルになったな．1に関しては死ぬほど研究されているので，その中から適用な手法を使うことにする． ここでは，PPMIを使って単語ベクトルを決定してみる．この辺は特に珍しくもないので，例えば以下を参照してください．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cl.ecei.tohoku.ac.jp/nlp100/&quot; title=&quot;http://www.cl.ecei.tohoku.ac.jp/nlp100/&quot;&gt;http://www.cl.ecei.tohoku.ac.jp/nlp100/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;残る問題は２だ．とりあえずシンプルさを追求して，単語の出現回数を使うことにする．つまり，&lt;script type=&quot;math/tex&quot;&gt;\alpha^{(d)}_i=c(w_i,d)&lt;/script&gt;とする． ただし，&lt;script type=&quot;math/tex&quot;&gt;c(w_i,d)&lt;/script&gt;は，文書&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;における単語&lt;script type=&quot;math/tex&quot;&gt;w_i&lt;/script&gt;の出現回数である． これで全ての問題が一応解決した．さあ，あとは実装するだけ．&lt;/p&gt;

&lt;div id=&quot;outline-container-sec-3&quot; class=&quot;outline-2&quot;&gt;
&lt;h2 id=&quot;sec-3&quot;&gt;実装&lt;/h2&gt;
&lt;div class=&quot;outline-text-2&quot; id=&quot;text-3&quot;&gt;
 コードは後日載せます． やっていることは，PPMIを要素とした単語-文脈行列を作り，その各行を単語ベクトルとします． あとは↑の定式化通りに文書ベクトルを生成し，文書分類器を作ります． その後，単語ベクトルたちを分類器にかけます． 文書分類器には，ロジスティック回帰（sklearn.linear_model.LogisticRegressionCV）を用います． デフォルト設定です（アプローチの可能性を見たいだけなので）． 
&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;sec-4&quot;&gt;実験&lt;/h2&gt;
&lt;p&gt;データはnaverまとめからクロールしたものを使う． カテゴリとそれに対応するクロールした文書数を以下の表に示す． これが今回の訓練データ．&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;カテゴリ&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;文書数&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ガールズ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;600&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ニュース・ゴシップ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;976&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;エンタメ・カルチャー&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;480&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;おでかけ・グルメ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;867&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;暮らし・アイデア&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;737&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;レシピ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;702&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;カラダ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;708&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ビジネススキル&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;558&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;IT・ガジェット&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;231&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;デザイン・アート&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;479&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;雑学&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;667&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;おもしろ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;584&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;定番&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;257&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;総異なり語数は14767件で，これが今回の分類対象となる． さて，結果はただ単語を羅列してもおもしろくないので，wordcloudを使おうと思う． これについては以下を参考にしました，ありがとうございます．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://qiita.com/kenmatsu4/items/9b6ac74f831443d29074&quot; title=&quot;http://qiita.com/kenmatsu4/items/9b6ac74f831443d29074&quot;&gt;http://qiita.com/kenmatsu4/items/9b6ac74f831443d29074&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;outline-container-sec-4-1&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-1&quot;&gt;ガールズ&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-1&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-girls.png&quot; alt=&quot;girls.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-2&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-2&quot;&gt;ニュース・ゴシップ&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-2&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-news.png&quot; alt=&quot;news.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-3&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-3&quot;&gt;エンタメ・カルチャー&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-3&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-entertainment.png&quot; alt=&quot;entertainment.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-4&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-4&quot;&gt;おでかけ・グルメ&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-4&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-spot.png&quot; alt=&quot;spot.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-5&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-5&quot;&gt;暮らし・アイデア&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-5&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-life.png&quot; alt=&quot;life.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-6&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-6&quot;&gt;レシピ&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-6&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-recipe.png&quot; alt=&quot;recipe.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-7&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-7&quot;&gt;カラダ&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-7&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-wellness.png&quot; alt=&quot;wellness.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-8&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-8&quot;&gt;ビジネススキル&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-8&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-business.png&quot; alt=&quot;business.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-9&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-9&quot;&gt;IT・ガジェット&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-9&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-tech.png&quot; alt=&quot;tech.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-10&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-10&quot;&gt;デザイン・アート&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-10&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-design.png&quot; alt=&quot;design.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-11&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-11&quot;&gt;雑学&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-11&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-trivia.png&quot; alt=&quot;trivia.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-12&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-12&quot;&gt;おもしろ&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-12&quot;&gt;
&lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/09/wpid-humor.png&quot; alt=&quot;humor.png&quot; /&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;outline-container-sec-4-13&quot; class=&quot;outline-3&quot;&gt;
&lt;h3 id=&quot;sec-4-13&quot;&gt;定番&lt;/h3&gt;
&lt;div class=&quot;outline-text-3&quot; id=&quot;text-4-13&quot;&gt;
 該当単語なし 
&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;sec-5&quot;&gt;おわりに&lt;/h2&gt;
&lt;p&gt;今回はラベル付き文書データから文書分類器を学習し，それを単語分類に使用してみた． 結果は定性的に測るしかないが，うまくいっているところはあるのでアプローチは悪くないのかなと思う． 定番に該当がないのは定番だからなのだろうか？笑 ただ，もっと分類器をチューニングしたほうが良い気がする． いまはただロジスティック回帰にぶん投げているだけなので．&lt;/p&gt;

&lt;p&gt;次回は，教師あり次元削減，具体的にはFisher Discriminant Analysis (FDA)をかけてみます． いまは生の単語-文脈行列を使っているので，情報をもっと圧縮させて次元を削減しようと思います． さらに，教師ありデータを使うことで，同じラベルを持つものは近くなり，異なるラベルを持つものは遠くなるよう次元削減後の空間を学習します（正確には射影行列）． まぁとりあえずいいんではなかろうか．&lt;/p&gt;

</description>
        <pubDate>Tue, 29 Sep 2015 20:33:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/machine%20learning/2015/09/29/29203300.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/machine%20learning/2015/09/29/29203300.html</guid>
        
        <category>Machine Learning</category>
        
        <category>python</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>RBF (Gaussian) Kernel Modelを使うためのWrapper Classを作りました</title>
        <description>&lt;p&gt;分類問題において，非線形な決定境界を表現するための一つの方法に，RBF Kernel Modelがあります． これは，入力$latex x$を以下で定義される$latex \phi(x)$に変換するものです．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\phi_i(x)=\exp\left(-\gamma\|x-x_i\|\right), \ \forall i=1,\ldots,n
\end{align*}&lt;/script&gt;

&lt;p&gt;コードはGistに載せてあります：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/nkt1546789/e41199340f7a42c515be&quot; title=&quot;https://gist.github.com/nkt1546789/e41199340f7a42c515be&quot;&gt;https://gist.github.com/nkt1546789/e41199340f7a42c515be&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;使い方は，例えばsklearnのLogisticRegressionに適用したい場合は，&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RbfModelWrapper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;同様にRidgeに適用したい場合は，&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RbfModelWrapper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ridge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;ちなみにGridSearchもできるようになっています：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;gs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RbfModelWrapper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ridge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;gamma&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;alpha&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]})&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;とりあえずデモとして，2moonsを分類してみました：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.grid_search&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make_moons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;noise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=.&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ntr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ntr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ntr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;gamma&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RbfModelWrapper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_estimator_&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;accuracy:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;xx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;meshgrid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contour&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;colors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;green&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;blue&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;red&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;tight&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
           &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r&amp;quot;decision boundary&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;positive&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;unlabeled&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;prop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;size&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;lower right&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tight_layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;以下のように100%の精度で分類出来ました：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/rbfmodel_demo.png&quot; alt=&quot;image name&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 25 Aug 2015 08:03:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/uncategorized/2015/08/25/25080300.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/uncategorized/2015/08/25/25080300.html</guid>
        
        
        <category>Uncategorized</category>
        
      </item>
    
      <item>
        <title>ラプラス正則化 (Laplacian Regularization) を使った半教師付き分類</title>
        <description>&lt;p&gt;教師ありデータ&lt;script type=&quot;math/tex&quot;&gt;\{(x_i,y_i)\}_{i=1}^{n_l}&lt;/script&gt;と教師なしデータ&lt;script type=&quot;math/tex&quot;&gt;\{x_j\}_{j=n_l+1}^{n}&lt;/script&gt;を 用いて学習する枠組みを半教師付き学習と呼ぶ． 少量の教師ありデータと大量の教師なしデータを持っているという設定は非常に現実的で， 半教師付き学習は実用的な枠組みだと思う．&lt;/p&gt;

&lt;p&gt;ラプラス正則化の基本的なアイデアは，「似ているものは同じラベルを持つ」というもの． 具体的には，類似度行列&lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt;を受け取り， 類似度が高いものは予測値も近くなるような正則化を行う． 今回はラプラス正則化のリッジ回帰への適用例を考えてみる． ラプラス正則化を施したリッジ回帰の最適化問題は以下で与えられる．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\min_{\theta} \ \sum_{i=1}^{n_l} (y_i-f_{\theta}(x_i))^2 + \alpha \|\theta\|^2 + \beta \sum_{j=n_l+1}^{n} \sum_{k=n_l+1}^n W_{jk} (f_\theta(x_j)-f_\theta(x_k))^2
\end{align*}&lt;/script&gt;

&lt;p&gt;最後の項がラプラス正則化項． この項は結局ラプラス行列というもので表されるのでラプラス正則化と呼ばれている．&lt;/p&gt;

&lt;p&gt;ここでは，非線形な決定境界を表現するために，&lt;script type=&quot;math/tex&quot;&gt;f_\theta&lt;/script&gt;には以下で定義するRBFカーネルモデルを用いることにする．&lt;/p&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;$$ f_{\theta}(x) = \sum_{\ell=1}^n \theta_\ell k(x,x_\ell), \ k(x,x_\ell)=\exp\left(-\gamma\|x-x_\ell\|^2\right) $$&lt;/p&gt;
&lt;p&gt;コードは以下のようになった．&lt;/p&gt;

&lt;p&gt;https://gist.github.com/nkt1546789/add3f33ceee65294d0a8&lt;/p&gt;

&lt;p&gt;実行結果はこんな感じ． 左が訓練データで赤と青がラベル付きデータで白い点がラベルなしデータ． このように，たった2つの教師ありデータから正しく分類ができている．&lt;/p&gt;
&lt;div class=&quot;figure&quot;&gt;

&lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/07/wpid-laplacian_regularization_2moons.png&quot; alt=&quot;laplacian_regularization_2moons.png&quot; /&gt;

&lt;/div&gt;
&lt;div class=&quot;figure&quot;&gt;

&lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/07/wpid-laplacian_regularization_2circles.png&quot; alt=&quot;laplacian_regularization_2circles.png&quot; /&gt;

&lt;/div&gt;

&lt;p&gt;ちなみに，RBFカーネルモデルにすべてのデータ点を使っているものポイント．&lt;/p&gt;

&lt;p&gt;ラプラス正則化は目的関数に一つ項を加えるだけで， 教師なしデータも活用できるのでお手軽で性能も素晴らしいので是非使ってみてください．
もちろん，上の例のように，十分な量の訓練データが与えられていない場合，パラメータチューニングが非常に難しいです．
教師ありデータが十分にあれば，交差検定ができる．&lt;/p&gt;
</description>
        <pubDate>Sat, 25 Jul 2015 08:00:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/machine%20learning/python/2015/07/25/25080000.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/machine%20learning/python/2015/07/25/25080000.html</guid>
        
        
        <category>Machine Learning</category>
        
        <category>python</category>
        
      </item>
    
      <item>
        <title>BOW+TFIDFでニュース記事分類</title>
        <description>&lt;p&gt;前回：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://nktmemo.wordpress.com/2015/07/19/word2vectfidf%E3%81%A7%E3%83%8B%E3%83%A5%E3%83%BC%E3%82%B9%E8%A8%98%E4%BA%8B%E5%88%86%E9%A1%9E/&quot; title=&quot;word2vecでニュース記事分類&quot;&gt;word2vecでニュース記事分類&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の続き．というかこっちを先にするべきだった． 引き続きlivedoorニュースコーパスを使う． クラス数は9で総文書数は7356件． 今回の対象はタイトルと全文． なので各文書がある程度長いことを想定 （次回はここをタイトルのみにして短い文書に対する分類結果も出してみる）．&lt;/p&gt;

&lt;p&gt;前回はword2vecを使ったが， 今回は普通にBag-of-WordsモデルとそれにTFIDFで重み付けをしたものを比較してみる． 実験の設定は前回と同じなので，前回の結果とも比較できる． 各文書がある程度長いのでBOWでもいい結果が出るだろうと予測したが，どうなんだろうか．&lt;/p&gt;

&lt;p&gt;結果は以下のようになった．&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;BOW+TF&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;BOW+TFIDF&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;w2v&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.95 (0.004)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.95 (0.004)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.85 (0.007)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;検定はしていないが，おそらくBOW (+ TFIDF)はword2vecを使ったモデルよりも性能が良いと言っていいだろう． 以下の要因が考えられる．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;十分な数のトレーニングデータが与えられているため&lt;/li&gt;
  &lt;li&gt;文書がある程度長く，多くの単語を含むため&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;次回からは，このあたりを制限していって，結果がどう変わるかを見ていこうと思う． あと，word2vecをこのコーパスでトレーニングしてもいいかも．&lt;/p&gt;

</description>
        <pubDate>Tue, 21 Jul 2015 20:53:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/uncategorized/2015/07/21/21205300.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/uncategorized/2015/07/21/21205300.html</guid>
        
        
        <category>Uncategorized</category>
        
      </item>
    
  </channel>
</rss>
