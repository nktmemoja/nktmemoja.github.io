<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nktmemo_ja</title>
    <description>nktmemo provides interesting articles about Machine Learning and NLP.
</description>
    <link>http://nktmemoja.github.io/</link>
    <atom:link href="http://nktmemoja.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 10 Jul 2016 22:57:17 +0900</pubDate>
    <lastBuildDate>Sun, 10 Jul 2016 22:57:17 +0900</lastBuildDate>
    <generator>Jekyll v3.0.0</generator>
    
      <item>
        <title>半教師ありページランクを用いたウェブページからの教師なしメインコンテンツ抽出</title>
        <description>&lt;h2 id=&quot;section&quot;&gt;はじめに&lt;/h2&gt;
&lt;p&gt;ウェブページ（HTML文書）はヘッダーフッダー，メニュー，広告など，自身の内容とは関係のない多くのノイズを含んでいます．
これらのノイズはウェブページ解析を非常に難しくさせています．
特に最近では，ページに関連した広告が貼られていたりするので，ウェブページ解析がさらに難しくなっているように思います．&lt;/p&gt;

&lt;p&gt;このような問題は昔から研究されていて，HTMLからのメインコンテンツ抽出 (Main Content Extraction)とか，本文抽出とか呼ばれています．
多くの既存手法は，DOMの構造を元にメインコンテンツに該当するDOM要素を特定します．
そのために，入念にスコア関数を設計したり，教師データから学習させたりする試みがなされています．
スコア関数や素性には，ほとんどと言っていいほどテキスト情報が使われます．
よって，これらはニュース記事など，そのページのメインコンテンツがテキストである場合，十分な性能が期待できます．&lt;/p&gt;

&lt;p&gt;しかしながら，ウェブページの中には，テキスト以外をメインコンテンツとするページもあります．
例えば，何かのメタ情報のみを掲載しているページや，動画や画像メインのページなどです．
このような場合，上記のような手法では，非常に少ないテキスト情報からメインコンテンツ部分を予測することになり，結果として性能の低下を生みます．
今回は，テキスト以外をメインコンテンツとするページにもある程度適用できるようなメインコンテンツ抽出アルゴリズムの構築を目指します．&lt;/p&gt;

&lt;h2 id=&quot;dom-pagerank-dom&quot;&gt;DOM PageRank: DOM要素への重み付け&lt;/h2&gt;
&lt;p&gt;以前，&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://nktmemoja.github.io/jekyll/update/2016/07/06/laplaciannodeweighting.html&quot; target=&quot;_blank&quot;&gt;ラプラス正則化を用いた半教師付きページランク&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を紹介しました．
半教師付きページランクを実行するには，隣接行列&lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt;と初期重み&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&lt;/script&gt;が必要です．
教師データを&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&lt;/script&gt;で表現すれば，その情報を活用できます．
今回はこれをメインコンテンツ抽出に応用したアルゴリズム，DOM PageRankを提案します．この場合，DOMツリーをそのまま隣接行列として与えれば，あとは初期値をどう決めるかの問題になります．&lt;/p&gt;

&lt;p&gt;具体的に定式化していきます．
&lt;script type=&quot;math/tex&quot;&gt;G=(V, E)&lt;/script&gt;をDOMツリーの&lt;strong&gt;有向&lt;/strong&gt;グラフ表現とします．
&lt;strong&gt;エッジの向きは，子供 -&amp;gt; 親とします&lt;/strong&gt;．
つまり，&lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt;がテキストノードを含むDOMの要素，&lt;script type=&quot;math/tex&quot;&gt;E&lt;/script&gt;がその間のエッジです．
&lt;script type=&quot;math/tex&quot;&gt;E&lt;/script&gt;を隣接行列&lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt;で表現します．ただし，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
A_{ij} =
\left\{\begin{array}{ll}
1 &amp; if \ (i,j) \in E \\
0 &amp; otherwise
\end{array}\right.
\end{align*}. %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&lt;/script&gt;をどう決めるかによって，結果が変わってきます．
基本的には，&lt;script type=&quot;math/tex&quot;&gt;u_i&lt;/script&gt;には&lt;script type=&quot;math/tex&quot;&gt;v_i&lt;/script&gt;が重要であればあるほど高い値を設定します．
&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&lt;/script&gt;の決定例を幾つか考えてみました．&lt;/p&gt;

&lt;p&gt;DOMツリー内の重要な要素とは何でしょうか？
とりあえず先人達と同じようにテキストノードは重要だと考えると，&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&lt;/script&gt;は以下のようになります（これをテキスト一様重みと呼びます）．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
u_i =
\left\{\begin{array}{ll}
1 &amp; \text{if} \ v_i \ \text{is a text node} \\
0 &amp; otherwise
\end{array}\right.
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;基本的には，テキスト一様重みで良さそうですが，
テキストの中には重要なものとそうでないものがあると考えられます．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://nktmemoja.github.io/jekyll/update/2016/07/07/sspagerank-webpageanalysis.html&quot; target=&quot;_blank&quot;&gt;半教師付きページランクを用いたウェブページ中の単語への重み付け&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;では，タイトルやディスクリプションと似たテキストは重要だと仮定しました．
今回もその仮定を採用してみます．具体的には&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&lt;/script&gt;を以下のように定義します（これをタイトル重みと呼びます）．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
u_i =
\left\{\begin{array}{ll}
(1-\beta) + \beta \left(sim(w_i, w_{title}) + sim(w_i, w_{desc})\right) &amp; \text{if} \ v_i \ \text{is a text node} \\
0 &amp; otherwise
\end{array}\right.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;ただし， &lt;script type=&quot;math/tex&quot;&gt;w_i&lt;/script&gt;は&lt;script type=&quot;math/tex&quot;&gt;v_i&lt;/script&gt;が持つテキスト，&lt;script type=&quot;math/tex&quot;&gt;w_{title}&lt;/script&gt;はタイトル，&lt;script type=&quot;math/tex&quot;&gt;w_{desc}&lt;/script&gt;はディスクリプション，&lt;script type=&quot;math/tex&quot;&gt;\beta \geq 0&lt;/script&gt;はトレードオフパラメータです．&lt;/p&gt;

&lt;p&gt;その他にも，画像や動画メインのページも考慮すると，&amp;lt;img&amp;gt;や&amp;lt;video&amp;gt;タグにも初期重みをいくらか与えることも考えられます．&lt;/p&gt;

&lt;p&gt;さて，これで&lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&lt;/script&gt;を元に，すべてのDOM要素&lt;script type=&quot;math/tex&quot;&gt;V = \{v_i\}_{i=1}^n&lt;/script&gt;に対して，重み&lt;script type=&quot;math/tex&quot;&gt;\{f_i\}_{i=1}^n&lt;/script&gt;が付きます．&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;メインコンテンツ抽出&lt;/h2&gt;
&lt;p&gt;半教師付きページランクにより，すべてのDOM要素&lt;script type=&quot;math/tex&quot;&gt;V = \{v_i\}_{i=1}^n&lt;/script&gt;に対して，重み&lt;script type=&quot;math/tex&quot;&gt;\{f_i\}_{i=1}^n&lt;/script&gt;が付きます．
次は，メインコンテンツ抽出にこのDOM要素への重みを活用します．
ここはあまり深く考えず，包括的にメインコンテンツを抽出するために，Sunらによって提案されたDensitySumを用います．
DensitySumでは，あるDOM要素&lt;script type=&quot;math/tex&quot;&gt;v_i&lt;/script&gt;のスコア&lt;script type=&quot;math/tex&quot;&gt;g_i&lt;/script&gt;を以下のように求めます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
g_i = \sum_{v_j \in Children(v_i)} f_j
\end{align*}&lt;/script&gt;

&lt;p&gt;つまり，あるDOM要素のスコアは，その子要素の合計値であると定義します．
Sunらはさらに抽出アルゴリズムも提案していますが，今回はシンプルにメインとなるDOM要素&lt;script type=&quot;math/tex&quot;&gt;\hat{v}&lt;/script&gt;を以下のように定義します．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\hat{v} = \text{argmax}_{i} \ g_i
\end{align*}&lt;/script&gt;

&lt;h2 id=&quot;section-2&quot;&gt;実験&lt;/h2&gt;
&lt;p&gt;実験してみました．
今回は，教師ありメインコンテンツ抽出アルゴリズムである，dragnetと比較してみます．&lt;/p&gt;

&lt;p&gt;とりあえず画像メインのページとして，&lt;a href=&quot;http://curazy.com/archives/142844&quot; target=&quot;_blank&quot;&gt;癒されたい人集合！一生離れないと誓った「にこいちアニマル」に悶える12選 | CuRAZY [クレイジー]&lt;/a&gt;を選びました．抽出結果を以下の表に示します（今回はテキストで示しますが，実際にはDOM要素を取得できます）．
なお&lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;は正則化パラメータで，&lt;strong&gt;大体0.5にしとけば良さそうです&lt;/strong&gt;．&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;手法&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;抽出したテキスト&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;DOM Page Rank (テキスト一様重み, &lt;script type=&quot;math/tex&quot;&gt;\alpha=0.5&lt;/script&gt;）&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Facebook でシェアする Twitter でシェアする LINE で送る ネコ部を フォローする クレイジーの最新記事 をお届けします &lt;font color=&quot;blue&quot;&gt;1. 窒息するギリギリまでギュッ View post on imgur.com 2. くっついてないと焦りだす View post on imgur.com 3. 夢の中でも二匹は一緒 http://bit.ly/16Yh5ll 4. ご主人が出かけると始まるダンスパーティー Boomer (Golden retriever) and Trigger (Lab) 5. ２匹にイタズラさせたら横に出る者はいない View post on imgur.com 6. 一緒にいると自然と笑顔に View post on imgur.com 7. 落ち込んだら片方が慰める View post on imgur.com 8. 溶けて１匹になっちゃいそう View post on imgur.com 9. どこにも行かないって約束！ http://catasters.tumblr.com/post/139548429975/thank-you-for-reminding-me-to-wish-you-a-happy 10. 愛が溢れ出ちゃってる View post on imgur.com 11. 他のワンコそっちのけ View post on imgur.com 12. 二人の間には誰も入れない View post on imgur.com Editor &lt;/font&gt;クレイジーピンク クレイジー特戦隊、唯一の女子隊員！ 最近Twitter始めました♡クレイジーガールなつぶやきしていくので、是非フォローしてください( ✧Д✧) 最近、習字道具を一式揃えました！ Twitter：https://twitter.com/curazypink クレイジーピンクの他の記事 local_offer 動物 ネコ大好き！ 仲良し 猫 犬 公園 桃 ドリンク 不運 この記事が気に入ったら いいね！しよう 最新記事をお届けします フォローしよう 友達に追加しよう&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;dragnet&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;レイジー特戦隊、唯一の女子隊員！ 最近Twitter始めました♡クレイジーガールなつぶやきしていくので、是非フォローしてください( ✧Д✧) Twitter：https://twitter.com/curazypink クレイジーピンクの他の記事&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;青字の部分がメインコンテンツです．DOM PageRankはメインコンテンツ前後の多少のノイズを含んではいるものの，うまく抽出できています．
一方でdragnetは完全に抽出に失敗しています．&lt;/p&gt;

&lt;p&gt;次に，さらにテキストの少ない店舗紹介ページ，&lt;a href=&quot;https://supermarket.geomedian.com/135498/&quot; target=&quot;_blank&quot;&gt;スーパーセンタートライアル宇部中央店｜全国スーパーマーケット・ディスカウントショップマップ&lt;/a&gt;に適用してミアmす．
これに対する抽出結果を以下の表に示します．&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;手法&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;抽出したテキスト&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;DOM PageRank (テキスト一様重み, &lt;script type=&quot;math/tex&quot;&gt;\alpha=0.5&lt;/script&gt;）&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;font color=&quot;blue&quot;&gt;所在地 山口県 宇部市 中央町3-16-20 最寄駅 宇部新川駅 から直線距離で513m 宇部新川駅周辺の店舗一覧 ＞ トライアル 店舗のジャンル 激安スーパー トライアル 備考 2016年7月13日オープン予定！ 宇部市のトライアル店舗一覧 宇部市の全店舗一覧 最終更新： 2016年7月8日&lt;/font&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;dragnet&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;font color=&quot;blue&quot;&gt;所在地 山口県 宇部市 中央町3-16-20 最寄駅 宇部新川駅周辺の店舗一覧 ＞ トライアル 店舗のジャンル 激安スーパー トライアル 備考 2016年7月13日オープン予定！ 宇部市のトライアル店舗一覧 宇部市の全店舗一覧 最終更新： 2016年7月8日&lt;/font&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;両方ともメインコンテンツ抽出に成功していますが，DOM PageRankはより多くのコンテンツを抽出できています．&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;おわりに&lt;/h2&gt;
&lt;p&gt;今回は，半教師付きページランクをウェブページ（HTML文書）のメインコンテンツ抽出に応用してみました．
さらに，簡単ではありますが，dragnetと性能を比較し，その実用性を示しました．
半教師付きページランクは初期重みを変えることで柔軟にアルゴリズムを設計できるところに強みがあると思います．
パラメータも正則化パラメータのみです．
正直テキスト一様重みでこの結果が出たのは驚きですが，とりあえずよしとします…．&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;コード&lt;/h2&gt;
&lt;p&gt;コードはgistに載せています．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://gist.github.com/nkt1546789/dfc4f01dbf4aa8a9d32762e904865560&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/nkt1546789/dfc4f01dbf4aa8a9d32762e904865560&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一応ここにも載せておきます．&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/nkt1546789/dfc4f01dbf4aa8a9d32762e904865560.js&quot;&gt;&lt;/script&gt;

</description>
        <pubDate>Sun, 10 Jul 2016 18:34:32 +0900</pubDate>
        <link>http://nktmemoja.github.io/jekyll/update/2016/07/10/content-extraction-sspagerank.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/jekyll/update/2016/07/10/content-extraction-sspagerank.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>半教師付きページランクを用いたウェブページ中の単語への重み付け</title>
        <description>&lt;h2 id=&quot;section&quot;&gt;はじめに&lt;/h2&gt;
&lt;p&gt;前回&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://nktmemoja.github.io/jekyll/update/2016/07/06/laplaciannodeweighting.html&quot; target=&quot;_blank&quot;&gt;ラプラス正則化を用いた半教師付きページランク&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;というのを紹介してみました．
今回はこれをウェブページ中の単語への重み付けに応用してみます．
このアルゴリズムは半教師付きですが，教師データが自動的に得られる場合があります．
その一例が，ウェブページです．
ウェブページは&lt;meta /&gt;内にタイトルやディスクリプション，キーワードなどの重要な情報を持っています．
これにより，教師データがほぼ自動的に得られます．
ウェブページでなくとも，論文だと，タイトル・アブストラクトなどが得られますし，大体のテキストに適用できるのではないかと思います．&lt;/p&gt;

&lt;p&gt;単語への重み付けを，以下のように，半教師付きページランクの二段階適用によって行います．&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;テキストへの重み付け&lt;/li&gt;
  &lt;li&gt;単語への重み付け&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;なお，ここでいうテキストとは，DOMツリーの中のテキストノードが持つテキストを指します．&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;テキストへの重み付け&lt;/h3&gt;

&lt;p&gt;ウェブページ&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;を順序対を用いて&lt;script type=&quot;math/tex&quot;&gt;d = (w_1, \ldots, w_n)&lt;/script&gt;と表します（これはDOMツリーを深さ優先探索し，テキストノードだけ拾えば得られます）．
ただし，&lt;script type=&quot;math/tex&quot;&gt;w_i&lt;/script&gt;はテキストで，これも順序対を用いて
&lt;script type=&quot;math/tex&quot;&gt;w_i = (w_{i1},\ldots,w_{in_{i}})&lt;/script&gt;
と表します．ここで，&lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt;を&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;に出現する単語集合とし，&lt;script type=&quot;math/tex&quot;&gt;w_{ij} \in V&lt;/script&gt;とします．
本節では，&lt;script type=&quot;math/tex&quot;&gt;\{w_i\}_{i=1}^n&lt;/script&gt;への重み&lt;script type=&quot;math/tex&quot;&gt;\{f_{i}\}_{i=1}^n&lt;/script&gt;を獲得することを目的とします．
ただし，&lt;script type=&quot;math/tex&quot;&gt;f_i&lt;/script&gt;は&lt;script type=&quot;math/tex&quot;&gt;w_i&lt;/script&gt;への重みです．&lt;/p&gt;

&lt;p&gt;半教師付きページランクは，隣接行列&lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt; と，初期値&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&lt;/script&gt;を必要としますので，これを定義するだけで済みます．
まず，&lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt;を，以下で定義されるテキスト間の類似度行列とします．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A_{ij} = sim(w_i, w_j)&lt;/script&gt;

&lt;p&gt;テキスト間類似度関数&lt;script type=&quot;math/tex&quot;&gt;sim&lt;/script&gt;はコサインでもジャッカードでもなんでもいいです．
次に，&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&lt;/script&gt;を，以下のように定義します．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;u_i =
sim(w_i, w_{title}) + sim(w_i, w_{desc})&lt;/script&gt;

&lt;p&gt;ただし，&lt;script type=&quot;math/tex&quot;&gt;w_{title}&lt;/script&gt;は&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;のタイトル，&lt;script type=&quot;math/tex&quot;&gt;w_{desc}&lt;/script&gt;はディスクリプションとします．
あるいはもう少し厳格に，以下のようにタイトルとディスクリプションだけ使うことも考えられます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
u_i =
\left\{\begin{array}{ll}
1 &amp; if \ w_i = w_{title} \ or \ w_i = w_{desc} \\
0 &amp; otherwise
\end{array}\right. %]]&gt;&lt;/script&gt;

&lt;p&gt;これで半教師付きページランクを適用するのに必要なものが揃いました．
あとは実行して，&lt;script type=&quot;math/tex&quot;&gt;\mathbf{f} = [f_1 \cdots f_n]&lt;/script&gt;を得ます．&lt;/p&gt;

&lt;p&gt;ここでやっていることは，まず，&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&lt;/script&gt;でもって，タイトルとディスクリプションは大事だということを表現しています．
さらに，隣接行列をテキスト間の類似度行列とすることで，半教師付きページランクがタイトルとディスクリプションに似ているテキストは重要だと判断します．&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;単語への重み付け&lt;/h3&gt;
&lt;p&gt;上でテキストの重要度を計算した後，単語への重み付けを実行します．
本節の目的はウェブページ&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;中に出現する単語集合&lt;script type=&quot;math/tex&quot;&gt;V=\{v_i\}_{i=1}^N&lt;/script&gt;への重み&lt;script type=&quot;math/tex&quot;&gt;\{g_i\}_{i=1}^N&lt;/script&gt;を獲得することです．&lt;/p&gt;

&lt;p&gt;ここでも半教師付きページランクを用います．
上と同じように隣接行列&lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&#39;&lt;/script&gt;を，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A&#39;_{ij} = sim&#39;(v_i, v_j),&lt;/script&gt;

&lt;p&gt;と定義します．
&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&#39;&lt;/script&gt;は，以下のように定義します．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
u&#39;_i =
\left\{\begin{array}{ll}
1 &amp; if \ v_i \in V_{title} \ or \ v_i \in V_{desc} \\
0 &amp; otherwise
\end{array}\right. %]]&gt;&lt;/script&gt;

&lt;p&gt;ただし，&lt;script type=&quot;math/tex&quot;&gt;V_{title}&lt;/script&gt;はタイトル中に出現する単語集合，&lt;script type=&quot;math/tex&quot;&gt;V_{desc}&lt;/script&gt;はディスクリプション中に出現する単語集合です．&lt;/p&gt;

&lt;p&gt;単語間類似度関数&lt;script type=&quot;math/tex&quot;&gt;sim&#39;&lt;/script&gt;の定義についてですが，
今回は，単語の分布仮設の意味での類似度とします．
分布仮設は簡単にいうと，「共起する単語が似ている単語は意味的に似ている」と言うものです．
これは，例えば文脈ベクトルのコサイン類似度で定義されます．
これを行うために，&lt;script type=&quot;math/tex&quot;&gt;C_{ij}&lt;/script&gt;を，&lt;script type=&quot;math/tex&quot;&gt;v_i&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;v_j&lt;/script&gt;が共起範囲&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;で共起した回数として，共起行列&lt;script type=&quot;math/tex&quot;&gt;\mathbf{C} = [\mathbf{c}_1 \cdots \mathbf{c}_N]&lt;/script&gt;を作ります．
&lt;script type=&quot;math/tex&quot;&gt;v_i&lt;/script&gt;の文脈ベクトルは&lt;script type=&quot;math/tex&quot;&gt;\mathbf{c}_i&lt;/script&gt;に対応します．
ここで，&lt;script type=&quot;math/tex&quot;&gt;sim&#39;&lt;/script&gt;を以下のように定義します．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;sim&#39;(v_i, v_j) = \frac{\langle \mathbf{c}_i, \mathbf{c}_j \rangle}{\|\mathbf{c}_i\|\|\mathbf{c}_j\|}&lt;/script&gt;

&lt;p&gt;以上の定義で半教師付きページランクを適用することにより，単語への重み&lt;script type=&quot;math/tex&quot;&gt;\mathbf{g} = [g_1 \cdots g_N]&lt;/script&gt;が得られます．&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;実験&lt;/h2&gt;
&lt;p&gt;実験してみました．
今回は結果をtf (term frequency)と比較します．
本当はtfidfと比較したいのですが，idfがコーパス依存なので，tfだけと比較します．&lt;/p&gt;

&lt;p&gt;データとしては，比較的ノイズが多いページを選びました．
ノイズというのは，ヘッダーフッター，メニュー，広告などを指します．
最近のウェブページはこのような多くのノイズを含んでいます．
最近では，広告配信業者がページの内容に応じて関連の高い広告を埋め込んでいたりするので，ウェブページの解析がより難しくなっているように思います…．&lt;/p&gt;

&lt;p&gt;話がそれましたが，以下の二つのURLをデータとします．&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.lifehacker.jp/2016/07/160702_grilledapple.html&quot; target=&quot;_blank&quot;&gt;屋外料理のデザートに、スモーキーで甘い「りんごのグリル」はいかが？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://tabelog.com/shizuoka/A2201/A220102/22000892/dtlrvwlst/37192867/?lid=unpickup_review&quot; target=&quot;_blank&quot;&gt;『生しらす！』by 0141 : 和食処 するが蕎 - 蒲原/そば [食べログ]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://curazy.com/archives/142844&quot; target=&quot;_blank&quot;&gt;癒されたい人集合！一生離れないと誓った「にこいちアニマル」に悶える12選 | CuRAZY [クレイジー]&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1, 2, 3に対する結果をそれぞれ表1, 2, 3に示します．
なお，タイトルに出現する単語は表示していません．
TFより明らかに良い結果となっていると思います．
ただ，ページ3のように画像メインのページだと情報が少なくてほとんどの要素が0になってしまいます．
これは，外部情報，例えばword2vecなどを用いて&lt;script type=&quot;math/tex&quot;&gt;sim&#39;&lt;/script&gt;を定義してやるといいかもしれません．&lt;/p&gt;

&lt;p&gt;今回は可能性をみたかっただけなので，定性評価してしませんが，定量評価も比較的容易にできると思います．
というのも，この手法はよくあるDOM構造を利用したメインコンテンツ抽出とは違って，DOM構造に非依存なので，
同じドメインのページを大量に集めてテストしても大丈夫だと思います．
そういう意味ではパラメータもチューニングも自動化できるかもしれません．&lt;/p&gt;

&lt;p&gt;次回は，word2vecなどを使って，性能改善を図りたいと思います．&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;表1&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;提案法&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt; &lt;/th&gt;
      &lt;th&gt;TF&lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;順位&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;単語&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;スコア&lt;/th&gt;
      &lt;th&gt;単語&lt;/th&gt;
      &lt;th&gt;スコア&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;サイド&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.028785&lt;/td&gt;
      &lt;td&gt;title&lt;/td&gt;
      &lt;td&gt;0.01176&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;紹介&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.027523&lt;/td&gt;
      &lt;td&gt;トラブル&lt;/td&gt;
      &lt;td&gt;0.00941&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;food&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.021117&lt;/td&gt;
      &lt;td&gt;エアコン&lt;/td&gt;
      &lt;td&gt;0.00941&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;bbq&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.020636&lt;/td&gt;
      &lt;td&gt;男女&lt;/td&gt;
      &lt;td&gt;0.00941&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;肉&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.019335&lt;/td&gt;
      &lt;td&gt;温度&lt;/td&gt;
      &lt;td&gt;0.00941&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ディッシュ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.018379&lt;/td&gt;
      &lt;td&gt;設定&lt;/td&gt;
      &lt;td&gt;0.00941&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;メニュー&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.018254&lt;/td&gt;
      &lt;td&gt;staff&lt;/td&gt;
      &lt;td&gt;0.00706&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;考え&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.018254&lt;/td&gt;
      &lt;td&gt;by&lt;/td&gt;
      &lt;td&gt;0.00706&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;即座&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.017824&lt;/td&gt;
      &lt;td&gt;about&lt;/td&gt;
      &lt;td&gt;0.00706&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;フルーツ&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.013205&lt;/td&gt;
      &lt;td&gt;advertising&lt;/td&gt;
      &lt;td&gt;0.00706&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;メリット&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.010944&lt;/td&gt;
      &lt;td&gt;lifehacker&lt;/td&gt;
      &lt;td&gt;0.00706&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;12&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;概念&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.010802&lt;/td&gt;
      &lt;td&gt;privacy&lt;/td&gt;
      &lt;td&gt;0.00706&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;13&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;アイデア&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.010072&lt;/td&gt;
      &lt;td&gt;inc&lt;/td&gt;
      &lt;td&gt;0.00706&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;14&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;グラニースミス&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.006758&lt;/td&gt;
      &lt;td&gt;生活&lt;/td&gt;
      &lt;td&gt;0.00706&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;15&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;酸味&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.006684&lt;/td&gt;
      &lt;td&gt;mediagene&lt;/td&gt;
      &lt;td&gt;0.00706&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;16&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;最適&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.006622&lt;/td&gt;
      &lt;td&gt;サイド&lt;/td&gt;
      &lt;td&gt;0.00706&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;17&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;リンク&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.006463&lt;/td&gt;
      &lt;td&gt;方法&lt;/td&gt;
      &lt;td&gt;0.00706&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;18&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;参照&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.006408&lt;/td&gt;
      &lt;td&gt;hot&lt;/td&gt;
      &lt;td&gt;0.00471&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;19&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ベーコン&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.006405&lt;/td&gt;
      &lt;td&gt;円満&lt;/td&gt;
      &lt;td&gt;0.00471&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;20&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;フレーバー&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.00639&lt;/td&gt;
      &lt;td&gt;旅行&lt;/td&gt;
      &lt;td&gt;0.00471&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;表2&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;提案法&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt; &lt;/th&gt;
      &lt;th&gt;TF&lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;順位&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;単語&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;スコア&lt;/th&gt;
      &lt;th&gt;単語&lt;/th&gt;
      &lt;th&gt;スコア&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;店舗&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000829&lt;/td&gt;
      &lt;td&gt;口コミ&lt;/td&gt;
      &lt;td&gt;0.0344234079174&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;清水&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000766&lt;/td&gt;
      &lt;td&gt;名&lt;/td&gt;
      &lt;td&gt;0.0249569707401&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;蕎麦&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.00076&lt;/td&gt;
      &lt;td&gt;店&lt;/td&gt;
      &lt;td&gt;0.0240963855422&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;天ぷら&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000521&lt;/td&gt;
      &lt;td&gt;件&lt;/td&gt;
      &lt;td&gt;0.0163511187608&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;うどん&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000492&lt;/td&gt;
      &lt;td&gt;点数&lt;/td&gt;
      &lt;td&gt;0.013769363167&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;情報&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000431&lt;/td&gt;
      &lt;td&gt;位&lt;/td&gt;
      &lt;td&gt;0.012908777969&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;茶漬け&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000357&lt;/td&gt;
      &lt;td&gt;店舗&lt;/td&gt;
      &lt;td&gt;0.0111876075731&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;揚げ物&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000197&lt;/td&gt;
      &lt;td&gt;情報&lt;/td&gt;
      &lt;td&gt;0.0103270223752&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;定食&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000157&lt;/td&gt;
      &lt;td&gt;ランキング&lt;/td&gt;
      &lt;td&gt;0.0103270223752&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;食堂&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000157&lt;/td&gt;
      &lt;td&gt;蕎麦&lt;/td&gt;
      &lt;td&gt;0.00946643717728&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;郷土料理&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000155&lt;/td&gt;
      &lt;td&gt;定食&lt;/td&gt;
      &lt;td&gt;0.00860585197935&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;12&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;料理&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000122&lt;/td&gt;
      &lt;td&gt;清水&lt;/td&gt;
      &lt;td&gt;0.00860585197935&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;13&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;魚介&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000122&lt;/td&gt;
      &lt;td&gt;クーポン&lt;/td&gt;
      &lt;td&gt;0.00860585197935&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;14&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;丼&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.00011&lt;/td&gt;
      &lt;td&gt;訪問&lt;/td&gt;
      &lt;td&gt;0.00774526678141&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;15&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;重&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;8.1e-05&lt;/td&gt;
      &lt;td&gt;食堂&lt;/td&gt;
      &lt;td&gt;0.00774526678141&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;16&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;海鮮料理&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;5.5e-05&lt;/td&gt;
      &lt;td&gt;天ぷら&lt;/td&gt;
      &lt;td&gt;0.00774526678141&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;17&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;桜えび&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4.4e-05&lt;/td&gt;
      &lt;td&gt;桜えび&lt;/td&gt;
      &lt;td&gt;0.00774526678141&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;18&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;詳細&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4.3e-05&lt;/td&gt;
      &lt;td&gt;料理&lt;/td&gt;
      &lt;td&gt;0.00774526678141&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;19&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;青柳&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4.3e-05&lt;/td&gt;
      &lt;td&gt;特集&lt;/td&gt;
      &lt;td&gt;0.00774526678141&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;20&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;穴子&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4.2e-05&lt;/td&gt;
      &lt;td&gt;無料&lt;/td&gt;
      &lt;td&gt;0.00688468158348&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;表3&lt;/td&gt;
      &lt;td&gt;提案法&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;TF&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;順位&lt;/td&gt;
      &lt;td&gt;単語&lt;/td&gt;
      &lt;td&gt;スコア&lt;/td&gt;
      &lt;td&gt;単語&lt;/td&gt;
      &lt;td&gt;スコア&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;animal&lt;/td&gt;
      &lt;td&gt;0.023053&lt;/td&gt;
      &lt;td&gt;com&lt;/td&gt;
      &lt;td&gt;0.03412&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;tumblr.&lt;/td&gt;
      &lt;td&gt;0.015184&lt;/td&gt;
      &lt;td&gt;post&lt;/td&gt;
      &lt;td&gt;0.0315&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;catasters&lt;/td&gt;
      &lt;td&gt;0.014318&lt;/td&gt;
      &lt;td&gt;imgur&lt;/td&gt;
      &lt;td&gt;0.02887&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;thank&lt;/td&gt;
      &lt;td&gt;0.014265&lt;/td&gt;
      &lt;td&gt;view&lt;/td&gt;
      &lt;td&gt;0.02887&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;you&lt;/td&gt;
      &lt;td&gt;0.012764&lt;/td&gt;
      &lt;td&gt;on&lt;/td&gt;
      &lt;td&gt;0.02887&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;自然&lt;/td&gt;
      &lt;td&gt;0.005529&lt;/td&gt;
      &lt;td&gt;24時&lt;/td&gt;
      &lt;td&gt;0.01837&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;笑顔&lt;/td&gt;
      &lt;td&gt;0.005529&lt;/td&gt;
      &lt;td&gt;インターネット&lt;/td&gt;
      &lt;td&gt;0.01837&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;for&lt;/td&gt;
      &lt;td&gt;0.005331&lt;/td&gt;
      &lt;td&gt;ネコ&lt;/td&gt;
      &lt;td&gt;0.01837&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;reminding&lt;/td&gt;
      &lt;td&gt;0.004836&lt;/td&gt;
      &lt;td&gt;大好き!&lt;/td&gt;
      &lt;td&gt;0.01575&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;me&lt;/td&gt;
      &lt;td&gt;0.004675&lt;/td&gt;
      &lt;td&gt;twitter&lt;/td&gt;
      &lt;td&gt;0.01575&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;to&lt;/td&gt;
      &lt;td&gt;0.004503&lt;/td&gt;
      &lt;td&gt;記事&lt;/td&gt;
      &lt;td&gt;0.01575&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;wish&lt;/td&gt;
      &lt;td&gt;0.00446&lt;/td&gt;
      &lt;td&gt;crazy&lt;/td&gt;
      &lt;td&gt;0.01312&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;a-ha&lt;/td&gt;
      &lt;td&gt;0.004407&lt;/td&gt;
      &lt;td&gt;匹&lt;/td&gt;
      &lt;td&gt;0.0105&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;ppy&lt;/td&gt;
      &lt;td&gt;0.003951&lt;/td&gt;
      &lt;td&gt;つぶやき&lt;/td&gt;
      &lt;td&gt;0.0105&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;記事&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;一緒&lt;/td&gt;
      &lt;td&gt;0.0105&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;メニュー&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;動画&lt;/td&gt;
      &lt;td&gt;0.00787&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;シェア&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;シェア&lt;/td&gt;
      &lt;td&gt;0.00787&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;ネコ&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;http://&lt;/td&gt;
      &lt;td&gt;0.00787&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;アプリ&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;犬&lt;/td&gt;
      &lt;td&gt;0.00787&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;動物&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;フォロー&lt;/td&gt;
      &lt;td&gt;0.00787&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!--
このアルゴリズムにおける教師データは高い重みがついて欲しいノード集合なので，単語への重み付けの場合**高い重みがついて欲しい単語集合**になります．
これを$V^{*}$とします．

ウェブページはヘッダーフッター，メニュー，広告など多くのノイズを含んでいます．
最近では，広告配信業者がページの内容に応じて関連の高い広告を埋め込んでいたりするので，ウェブページの解析がより難しくなっているように思います．
しかしながら，**どんなにノイズが多くても，タイトル（とディスクリプション）は信頼できる**と考えられます．
というわけで，今回はタイトル（とディスクリプション）に含まれる単語集合を$V^{*}$$とします．
もちろんウェブページだけでなく，一般の文書にはタイトルがあると思うので，大体適用できると思います．

LNWを実行するには，$$V^{*}$$の他に，隣接行列$$\mathbf{A}$$が必要です．
今回は，これを共起行列とします．**重要な単語と共起する単語は重要**といった具合です．
これは，PageRankをテキストに応用したTextRankなんかと同じですね．
まとめると，

- $$V^{*}$$: タイトル（とディスクリプション）に出現する単語集合
- $$\mathbf{A}$$: 共起行列

とします．

# 実験
定性評価してみます．
対象は，

1. メインコンテンツがテキストのページ (&lt;a href=&quot;http://gigazine.net/news/20160706-santa-susana-nuclear-disaster/&quot; target=&quot;_blank&quot;&gt;http://gigazine.net/news/20160706-santa-susana-nuclear-disaster/&lt;/a&gt;)
2. そうでないページ (

1は例えばニュース記事などです．
2は例えば商品紹介ページだったり，画像や動画メインのページです．


|順位| 単語 |スコア|
|:---|:-----------------:|:-----------|
1 | アメリカ政府 |0.0108775415988|
2 | 徹底的 |0.0103866765743|
3 | 回避 |0.0102489698956|
4 | 放射性物質 |0.00826735437213|
5 | 表 |0.00688558477851|
6 | カリフォルニア州 |0.00687599731351|
7 | 完成 |0.00666602490429|
8 | 地球外生命 |0.00666602490429|
9 | 完全 |0.00662327332437|
10| 探査 |0.00654949037057|
11| fast |0.00654949037057|
12| 電波望遠鏡 |0.00654949037057|
13| 世界 |0.00654949037057|
14| 1979年 |0.00639230509713|
15| 危険 |0.00608159886266|
16| 例 |0.00597026076084|
17| 運用 |0.00586509783247|
18| カリフォルニア大学 |0.00578271053574|
19| 時点| 0.00554026259777|
20| アクシデント| 0.00532353224794|

図1: Gigazineへの適用結果&lt;br/&gt;



# おわりに
今回は，グラフノードへの重み付けアルゴリズムをウェブページに応用してみました．
ウェブページの解析といったら，メインコンテンツ抽出がよく研究されています．
画像や動画メインのページだと，メインとなるDOM要素を特定して，その中にある画像や動画を抽出する必要があります．
今回の応用例は，DOM要素の単語に重みをつけて，その合計値などでスコアをつければメインコンテンツ抽出にも使えると思います．
ちなみに，今回のアルゴリズムはDOM構造に依存していないので，同一ドメイン内で，評価やパラメータチューニングが簡単に行えることも強みだと思います．
--&gt;
</description>
        <pubDate>Thu, 07 Jul 2016 23:39:59 +0900</pubDate>
        <link>http://nktmemoja.github.io/jekyll/update/2016/07/07/sspagerank-webpageanalysis.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/jekyll/update/2016/07/07/sspagerank-webpageanalysis.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>ラプラス正則化を用いた半教師付きページランク</title>
        <description>&lt;p&gt;半教師付きの設定で，ページランクみたいにグラフのノードに重み付けをつけるアルゴリズム，半教師付きページランク (Semi-Supervised PageRank)を考えてみました．&lt;/p&gt;

&lt;p&gt;ページランクは，グラフのノードに重みをつけるアルゴリズムです．
一つやりたいことがあって，最初ページランクを使っていたのですが，教師的な情報を組み込むのが難しかったので，自分で考えることにしました．
というのも，ページランクでは，すべてのグラフノードの重みを1に初期化します．
単純にここに教師的な情報を組み込む，例えば数個のノードの重みを高くするなど，をやってみたのですが，最終的に出てくる解にあまり反映されなかったのです．
なぜなのか，をいろいろ考えましたが，ページランクはノードの重みを繰り返し伝搬するので，初期値が大事というより，エッジが大事なんだと今は思っています（もう少しちゃんと考える必要あり）．&lt;/p&gt;

&lt;p&gt;定式化していきましょう．
グラフ&lt;script type=&quot;math/tex&quot;&gt;G=(V, E), V=\{1, \ldots, n\}, E \subseteq V \times V&lt;/script&gt;を考えます．
扱いやすいように，エッジは隣接行列 (Adjacency matrix) &lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt;で表現することにします．
&lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt;をいろいろ変えることで，いろんなグラフが表現できますが，ここでは一般の行列にしときます．
重み付けにおける教師データとは何か？という話になると思うのですが，ここでは，高い（低い）重みがついて欲しいノードの集合&lt;script type=&quot;math/tex&quot;&gt;V^{*} \subseteq V&lt;/script&gt;が与えられることにします．&lt;/p&gt;

&lt;p&gt;さて，各ノードにおける重みを&lt;script type=&quot;math/tex&quot;&gt;\mathbf{f} = [f_1 \cdots f_n]&lt;/script&gt;と表すことにして，これを求めることがゴールになります．
とりあえず，&lt;script type=&quot;math/tex&quot;&gt;V^{*}&lt;/script&gt;の要素に該当する重みを大きくしたいので，&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u} = [u_1 \cdots u_n]&lt;/script&gt;を以下で定義します．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
u_i = \left\{\begin{array}{cc}
1 &amp; if \ i \in V^{*} \\
0 &amp; otherwise
\end{array}\right.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;こうすると，&lt;script type=&quot;math/tex&quot;&gt;V^{*}&lt;/script&gt;のスコアの合計値を，&lt;script type=&quot;math/tex&quot;&gt;\mathbf{f}^T \mathbf{u}&lt;/script&gt;と表すことができます．
今，&lt;script type=&quot;math/tex&quot;&gt;\mathbf{f}^T \mathbf{u}&lt;/script&gt;を最大化すれば良さそうですが，今回はラプラス正則化 (Laplacian Regularization) と呼ばれるものを加えます．
これは，ノード間にエッジが存在する場合，それらのスコアを近づける，というアイデアです．
ノード&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;の間にエッジが存在する，すなわち&lt;script type=&quot;math/tex&quot;&gt;A_{ij}=1&lt;/script&gt;なら&lt;script type=&quot;math/tex&quot;&gt;(f_i - f_j)^2&lt;/script&gt;を最小化します．
これは，&lt;script type=&quot;math/tex&quot;&gt;A_{ij}(f_i - f_j)^2&lt;/script&gt;と書けますね．これをすべてのノードに対してやります．
以上を踏まえて，以下の問題を解きます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
max_{\mathbf{f}} \ \mathbf{f}^T \mathbf{u} - \alpha \|\mathbf{f}\|^2 - \beta \sum_{i,j=1}^n A_{ij}(f_i - f_j)^2
\end{align*}&lt;/script&gt;

&lt;p&gt;ただし，第2項にl-2正則化項を加えています．
第3項がラプラス正則化項です．
これの解は以下のように解析的に得られます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\mathbf{f} = (\mathbf{L} + \gamma \mathbf{I}_n)^{-1} \mathbf{u}
\end{align*}&lt;/script&gt;

&lt;p&gt;ただし，&lt;script type=&quot;math/tex&quot;&gt;\mathbf{L} = \mathbf{D}-\mathbf{A}&lt;/script&gt;，&lt;script type=&quot;math/tex&quot;&gt;D_{ii} = \sum_{j=1}^n A_{ij}&lt;/script&gt;は対角行列，&lt;script type=&quot;math/tex&quot;&gt;\gamma=\frac{\alpha}{\beta}&lt;/script&gt;であり，これは通常の正則化パラメータと同じように事前に決めてやるものとします．
これで，望ましい結果というのを，&lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt;だけでなく，&lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&lt;/script&gt;でも表現できるようになりました．
次回は，これをウェブページ解析に応用したいと思います．&lt;/p&gt;
</description>
        <pubDate>Thu, 07 Jul 2016 00:48:19 +0900</pubDate>
        <link>http://nktmemoja.github.io/jekyll/update/2016/07/07/laplaciannodeweighting.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/jekyll/update/2016/07/07/laplaciannodeweighting.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Topic Modelの最尤推定の解の導出</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://www.amazon.co.jp/gp/product/4061529048/ref=as_li_ss_tl?ie=UTF8&amp;amp;camp=247&amp;amp;creative=7399&amp;amp;creativeASIN=4061529048&amp;amp;linkCode=as2&amp;amp;tag=nettodesyuu00-22&quot;&gt;トピックモデル (機械学習プロフェッショナルシリーズ)&lt;/a&gt;&lt;img src=&quot;http://ir-jp.amazon-adsystem.com/e/ir?t=nettodesyuu00-22&amp;amp;l=as2&amp;amp;o=9&amp;amp;a=4061529048&quot; width=&quot;1&quot; height=&quot;1&quot; border=&quot;0&quot; alt=&quot;&quot; style=&quot;border:none !important; margin:0px !important;&quot; /&gt;の3.4章の解の導出です．LaTeX書くのが面倒なので画像で．．．笑&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://nktmemoja.github.io/assets/CDEA4F6D-2A70-4053-87F7-B5D307125B2C.jpg&quot; alt=&quot;topic modelの最尤推定の解の導出1&quot; /&gt;
&lt;img src=&quot;http://nktmemoja.github.io/assets/BE1823C6-24EB-440A-A6CC-61E15CC7C645.jpg&quot; alt=&quot;topic modelの最尤推定の解の導出1&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 01 Jul 2016 01:07:03 +0900</pubDate>
        <link>http://nktmemoja.github.io/jekyll/update/2016/07/01/topicmodel.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/jekyll/update/2016/07/01/topicmodel.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Adjusted Rand Index (ARI) について勉強してみた</title>
        <description>&lt;p&gt;クラスタリングの性能評価でよくAdjusted Rand Index (ARI) が使われます．
僕もよく使っていますが，お恥ずかしながらよく知らずに使っていました．
というのも，Rand Index (RI) は理解できるのですが，ARIのAdjustedの意味がよくわかりませんでした．
というわけで，勉強してみました．&lt;/p&gt;

&lt;p&gt;まず，クラスタリングは，サンプル&lt;script type=&quot;math/tex&quot;&gt;S = \{o_i\}_{i=1}^n&lt;/script&gt;を&lt;script type=&quot;math/tex&quot;&gt;k (1 \leq k \leq n)&lt;/script&gt;個の互いに素なグループに分けることを目的とします．
この記事では，真のクラスタリング結果と，クラスタリングアルゴリズムの結果が似ているかどうかを測ることを目的とします．
なお，ここでは，クラスタリングの結果をクラスタラベルで表現することにします．&lt;/p&gt;

&lt;p&gt;さて，&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;に対する，
真のクラスタラベルを&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{\ell}=[\ell_1 \cdots \ell_n], \ell_i \in \{1, \ldots, k\} \forall i=1, \ldots, n&lt;/script&gt;，
クラスタリングアルゴリズムによるクラスタラベルを&lt;script type=&quot;math/tex&quot;&gt;\hat{ \boldsymbol{\ell}}=[\hat{\ell}_1 \cdots \hat{\ell}_n], \hat{\ell}_i \in \{1, \ldots, \hat{k}\} \forall i=1, \ldots, n&lt;/script&gt;とします．
クラスタリングの結果は，分類のようにラベルで考えるのではなく，ラベルのペアで考えます．
つまり，「このサンプルとこのサンプルは同じクラスタに属するか否か」で性能を評価します．
というわけで，&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{\ell}&lt;/script&gt;と &lt;script type=&quot;math/tex&quot;&gt;\hat{\boldsymbol{\ell}}&lt;/script&gt;を以下のように表現し直します．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathcal{X} &amp;= \{I(\ell_i = \ell_j) | (i,j) \in C(n, 2)\} = \{x_i\}_{i=1}^m\\
\mathcal{Y} &amp;= \{I(\hat{\ell}_i = \hat{\ell}_j) | (i,j) \in C(n, 2)\} = \{y_i\}_{i=1}^m
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;ただし，&lt;script type=&quot;math/tex&quot;&gt;m={}_n C _2&lt;/script&gt;．
さて，ここで，Rand Indexの定義を見てみます．
正規化されていないRand Indexは次式で定義されます（自己流です）．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
RI(x, y) = \sum_{i=1}^m I(x_i=y_i)
\end{align*}&lt;/script&gt;

&lt;p&gt;ただし，&lt;script type=&quot;math/tex&quot;&gt;I&lt;/script&gt;は指示関数で，&lt;script type=&quot;math/tex&quot;&gt;I(true) = 1, I(false) = 0&lt;/script&gt;です．
この式は，&lt;script type=&quot;math/tex&quot;&gt;x_i=y_i&lt;/script&gt; の数を表しており，二つのクラスタリングがどのくらい似ているかを表しています．&lt;/p&gt;

&lt;p&gt;よくRIの欠点として，「二つのクラスタリングに相関がなくても，高い値をとってしまう」という説明がなされます．
これの意味は，「適当（ランダム）にクラスタリングしても高い値をとってしまう」ということだと思います．
&lt;script type=&quot;math/tex&quot;&gt;x_i = 0&lt;/script&gt;となる&lt;script type=&quot;math/tex&quot;&gt;\mathcal{X}&lt;/script&gt;内の要素数が，&lt;script type=&quot;math/tex&quot;&gt;x_i = 1&lt;/script&gt;となる要素数に比べて圧倒的に多いので，
例えば「全てを異なるクラスタに分ける」というクラスタリングを行うと，&lt;script type=&quot;math/tex&quot;&gt;y_i = 0&lt;/script&gt;となり，RIの値が高くなってしまいます．
これは，分類問題において，クラスバランスが偏った状態で精度を使うのが適切ではない理由に似ています．&lt;/p&gt;

&lt;p&gt;このような問題を解決しようと提案されたのがARIです．
ARIでは，適当に行われたであろうクラスタリングにペナルティを与えます．
どのようなペナルティが適切でしょうか？
ARIでは，ペナルティ＝「適当にクラスタリングした時のRIの値」と考えます．
以下このペナルティを求めていきます．&lt;/p&gt;

&lt;p&gt;まず，二つのデータ&lt;script type=&quot;math/tex&quot;&gt;\mathcal{X}, \mathcal{Y}&lt;/script&gt;がぞれぞれ独立に同一の分布&lt;script type=&quot;math/tex&quot;&gt;p(x), p(y)&lt;/script&gt;から生成されたと仮定します：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\mathcal{X} \stackrel{i.i.d.}{\sim} p(x)\\
\mathcal{Y} \stackrel{i.i.d.}{\sim} p(y)
\end{align*}&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;p(x)&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;p(y)&lt;/script&gt;はそれぞれ確率変数&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;の従う分布に対応する確率密度関数を表します．
まず，上で定義したペナルティ中の「適当にクラスタリングした時」というのを，「&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;が独立な時」と定義します．
そうすると，求めるペナルティは「&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;が独立な時のRIの値」となり，具体的になりました．
そのようなペナルティは，以下で求められます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathbb{E}_{(x,y) \sim p(x,y)}\left[RI\right]
&amp;= \mathbb{E}_{(x,y) \sim p(x,y)}\left[ \sum_{i=1}^m I(x_i=y_i) \right] \\
&amp;= \sum_{x=0}^1 \sum_{y=0}^1 \sum_{i=1}^m I(x_i=y_i) p(x, y) \\
&amp;= \sum_{i=1}^m \left( p(x=1, y=1) + p(x=0, y=0) \right) \\
&amp;= m \left( p(x=1, y=1) + p(x=0, y=0) \right) \\
&amp;= m \left( p(x=1)p(y=1) + p(x=0)p(y=0) \right)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;最後の変形は&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;の独立性を使いました．
&lt;script type=&quot;math/tex&quot;&gt;p(x=0), p(x=1), p(y=0), p(y=1)&lt;/script&gt;は未知なので，データから推定してやらねばなりません．
ここでは，以下のように，最尤推定で求めることにしましょう．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
p(x=1) &amp;= \frac{1}{m} \sum_{i=1}^m x_i, \ p(x=0) = 1 - p(x=1) \\
p(y=1) &amp;= \frac{1}{m} \sum_{i=1}^m y_i, \ p(y=0) = 1 - p(y=1)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;無事上で定義したペナルティをもとめることができました．
RIから求めたペナルティを引けば，ARIの完成になります：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
ARI(x, y) = \sum_{i=1}^m I(x_i=y_i) - \mathbb{E}_{(x,y) \sim p(x,y)}\left[RI\right]
\end{align*}&lt;/script&gt;

&lt;p&gt;通常，RIは以下のように，0から1の値をとるように正規化して使われます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
normalized RI(x, y) = \frac{1}{m} \sum_{i=1}^m I(x_i=y_i)
\end{align*}&lt;/script&gt;

&lt;p&gt;なので，正規化したARIは以下のようになります．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
normalized ARI(x, y) = \frac{\sum_{i=1}^m I(x_i=y_i) - \mathbb{E}_{(x,y) \sim p(x,y)}\left[RI\right]}{m-\mathbb{E}_{(x,y) \sim p(x,y)}\left[RI\right]} 
\end{align*}&lt;/script&gt;

&lt;p&gt;Wikipediaの定義式なんかと一致するのを示したほうが良かったですね…．
時間があれば追記しておきます．
なお，具体例は以下のページが参考になります．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://y-uti.hatenablog.jp/entry/2014/01/19/133936&quot; target=&quot;_blank&quot;&gt;http://y-uti.hatenablog.jp/entry/2014/01/19/133936&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 24 May 2016 19:46:44 +0900</pubDate>
        <link>http://nktmemoja.github.io/jekyll/update/2016/05/24/ari.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/jekyll/update/2016/05/24/ari.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>ソフトマージンSVMのヒンジ損失最小化学習としての解釈とその実装</title>
        <description>&lt;p&gt;前回，&lt;a href=&quot;http://nktmemoja.github.io/jekyll/update/2016/01/07/hardmarginsvmformulation.html&quot;&gt;ハードマージンSVMの定式化&lt;/a&gt;について書いたので，
今回はソフトマージンSVMの定式化をしようと思います．
さらに，それをヒンジ損失最小化学習として解釈できることを示し，
最後に確率的勾配法を使って実装したいと思います．&lt;/p&gt;

&lt;p&gt;さて，ハードマージンSVMの最適化問題は以下で与えられます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\min_{\boldsymbol{w},b} &amp;\ \|\boldsymbol{w}\|^2 \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1 \ \forall i=1,\ldots,n
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;しかし，与えられたデータに対して，この制約を満たす超平面が存在しない場合，実行可能領域が空集合となり，この最適化問題が解を持たなくなってしまいます．
そこで，制約を緩和するために，全てのサンプルに対して&lt;script type=&quot;math/tex&quot;&gt;\xi_i \geq 0&lt;/script&gt;を導入し，最適化問題を以下のように書き換えます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\min_{\boldsymbol{w},b,\{\xi_i\}_{i=1}^n} &amp;\ \|\boldsymbol{w}\|^2 + C \sum_{i=1}^n \xi_i\\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1-\xi_i \ \forall i=1,\ldots,n\\
&amp;\ \xi_i \geq 0 \ \forall i=1,\ldots,n
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;これは，訓練データでの誤識別をある程度許容することに相当します．
我々のゴールは汎化能力の獲得，つまり，未知のデータに対する誤識別率を最小化することなので，訓練データを全て正しく識別する必要はありません．
さらに，訓練データに完全にフィットさせることは，汎化能力の低下を引き起こす原因にもなります．そのような意味でも，制約の緩和は有用です．&lt;/p&gt;

&lt;p&gt;この最適化問題では，&lt;script type=&quot;math/tex&quot;&gt;\xi_i&gt;0&lt;/script&gt;の時，&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x}_i&lt;/script&gt;の誤識別を許容します．
さらに，&lt;script type=&quot;math/tex&quot;&gt;\xi_i&lt;/script&gt;は小さい方が望ましいので，目的関数に加えて同時に最小化します．
&lt;script type=&quot;math/tex&quot;&gt;C&lt;/script&gt;は識別率をコントロールするハイパーパラメータです．&lt;/p&gt;

&lt;p&gt;さて，ここで，&lt;script type=&quot;math/tex&quot;&gt;\xi_i&lt;/script&gt;を以下のように定義すると，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\xi_i = \max\{0,1-y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b)\}
\end{align*},&lt;/script&gt;

&lt;p&gt;上の最適化問題は，以下のように書き換えられます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\min_{\boldsymbol{w},b} \ \sum_{i=1}^n \max\{0,1-y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b)\} + \lambda \|\boldsymbol{w}\|^2
\end{align*}&lt;/script&gt;

&lt;p&gt;ここで，&lt;script type=&quot;math/tex&quot;&gt;\max\{0,1-y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b)\}&lt;/script&gt;を損失関数とみると，経験リスク最小化学習になっていることがわかります．損失関数&lt;script type=&quot;math/tex&quot;&gt;\ell_{hinge}(t) = \max\{0,1-t\}&lt;/script&gt;はヒンジ損失と呼ばれています．&lt;/p&gt;

&lt;p&gt;ここから実装について，書きたいと思います．
&lt;a rel=&quot;nofollow&quot; href=&quot;http://www.amazon.co.jp/gp/product/406152903X/ref=as_li_ss_tl?ie=UTF8&amp;amp;camp=247&amp;amp;creative=7399&amp;amp;creativeASIN=406152903X&amp;amp;linkCode=as2&amp;amp;tag=nettodesyuu00-22&quot; target=&quot;_blank&quot;&gt;オンライン機械学習 (機械学習プロフェッショナルシリーズ)&lt;/a&gt;&lt;img src=&quot;http://ir-jp.amazon-adsystem.com/e/ir?t=nettodesyuu00-22&amp;amp;l=as2&amp;amp;o=9&amp;amp;a=406152903X&quot; width=&quot;1&quot; height=&quot;1&quot; border=&quot;0&quot; alt=&quot;&quot; style=&quot;border:none !important; margin:0px !important;&quot; /&gt;を参考にしています．
SVMは二次計画法で解くこともできますが，今回は確率的勾配法（正確にはIncremental Gradient Method）を使って解きたいと思います．
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x} \in \mathbb{R}^{d+1}&lt;/script&gt; として，簡単のために &lt;script type=&quot;math/tex&quot;&gt;x_1 = 1&lt;/script&gt;とします．すると，切片&lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;が&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}&lt;/script&gt;に吸収され，上の最適化問題は，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\min_{\boldsymbol{w},b} \ \sum_{i=1}^n \max\{0,1-y_i\boldsymbol{w}^T \boldsymbol{x}_i\} + \lambda \|\boldsymbol{w}\|^2
\end{align*}&lt;/script&gt;

&lt;p&gt;と書けます．
確率的勾配法では，適当にサンプル&lt;script type=&quot;math/tex&quot;&gt;(\boldsymbol{x}_i,y_i)&lt;/script&gt;を一つ取り出して，それに対応する目的関数，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
J_i(\boldsymbol{w}) = \max\{0,1-y_i\boldsymbol{w}^T \boldsymbol{x}_i\} + \lambda \|\boldsymbol{w}\|^2
\end{align*},&lt;/script&gt;

&lt;p&gt;の勾配を求めます．その勾配&lt;script type=&quot;math/tex&quot;&gt;\nabla J_i(\boldsymbol{w})&lt;/script&gt;を用いて，パラメータを&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w} \leftarrow \boldsymbol{w} - \eta\nabla J_i(\boldsymbol{w})&lt;/script&gt;と更新します．これを収束まで繰り返します．&lt;/p&gt;

&lt;p&gt;しかし，ヒンジ損失は&lt;script type=&quot;math/tex&quot;&gt;1-y_i\boldsymbol{w}^T \boldsymbol{x}_i = 0&lt;/script&gt;を満たす点で微分不可能なため，劣勾配を考えます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\nabla J_i(\boldsymbol{w}) = \left\{
\begin{array}{ll}
-y_i\boldsymbol{x}_i + 2 \lambda \boldsymbol{w} &amp; (1-y_i\boldsymbol{w}^T \boldsymbol{x}_i \geq 0) \\
2 \lambda \boldsymbol{w} &amp; otherwise
\end{array}\right.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;これを踏まえると，アルゴリズムは以下のようになります．&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ランダムに&lt;script type=&quot;math/tex&quot;&gt;(\boldsymbol{x}_i,y_i) \in \{(\boldsymbol{x}_i,y_i)\}_{i=1}^n&lt;/script&gt;を取り出す．&lt;/li&gt;
  &lt;li&gt;以下のように&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}&lt;/script&gt;を更新 (&lt;script type=&quot;math/tex&quot;&gt;\eta&lt;/script&gt;はステップサイズ)&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\boldsymbol{w} \leftarrow
\boldsymbol{w} - \eta\left(2 \lambda \boldsymbol{w} + 
\left\{
\begin{array}{ll}
-y_i\boldsymbol{x}_i &amp; (1-y_i\boldsymbol{w}^T \boldsymbol{x}_i \geq 0) \\
0 &amp; otherwise
\end{array}\right.\right)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;実装してみました．
&lt;script src=&quot;https://gist.github.com/nktmemoja/15c7120a873f6195ee86.js&quot;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;結果は以下のようになりました．
&lt;img src=&quot;/assets/softmarginsvm_demo.png&quot; alt=&quot;softmarginsvm_demo.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;なお，以下に書いたように，実装においてはステップサイズの決定が非常に難しいです．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;[http://nktmemoja.github.io/jekyll/update/2016/01/10/gradient-method.html]&quot;&gt;勾配法で目的関数値は単調に減少していくのか？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;実際に使用する時は，scikit-learnのsklearn.linear_model.SGDClassifierを使うのが賢明でしょう．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html&quot; target=&quot;_blank&quot;&gt;http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今回はソフトマージンSVMを定式化し，確率的勾配法を用いて実装してみた．
とりあえず簡単な人工データでうまく動くことを確認した．
この実装は実用に耐えうるものではないので，簡単なデモだと思ってください^^．
読んでいただき，ありがとうございました．&lt;/p&gt;

</description>
        <pubDate>Mon, 11 Jan 2016 12:43:59 +0900</pubDate>
        <link>http://nktmemoja.github.io/jekyll/update/2016/01/11/softmarginsvm.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/jekyll/update/2016/01/11/softmarginsvm.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>勾配法で目的関数値は単調に減少していくのか？</title>
        <description>&lt;p&gt;目的関数&lt;script type=&quot;math/tex&quot;&gt;f: \mathbb{R}^d \rightarrow \mathbb{R}&lt;/script&gt;の最小化を考えましょう．
勾配法では，以下のようにパラメータ&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x}&lt;/script&gt;を更新していきます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\boldsymbol{x}_{k+1} = x_k - h_k \nabla f(\boldsymbol{x}_k), \ k=0,1,\ldots
\end{align*}&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;h_k &gt; 0&lt;/script&gt;はステップサイズ．&lt;/p&gt;

&lt;p&gt;1ステップ分の更新を考えましょう．
&lt;script type=&quot;math/tex&quot;&gt;y = \boldsymbol{x} - h_k \nabla f(\boldsymbol{x})&lt;/script&gt;とすると，我々が示したいのは，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
f(\boldsymbol{y}) \leq f(\boldsymbol{x})
\end{align*}.&lt;/script&gt;

&lt;p&gt;これだけではなにも議論できないので，これからは目的関数はリプシッツ連続 (Lipschitz continuous) だとします．
ではまずリプシッツ連続の定義から始めましょう．&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;Q \subseteq \mathbb{R}^d, L&gt;0&lt;/script&gt;に対して，集合&lt;script type=&quot;math/tex&quot;&gt;C^{k,p}_L(Q)&lt;/script&gt;を以下の性質を有する集合とします．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f \in C^{k,p}_L(Q)&lt;/script&gt; はk回微分可能で連続&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f^{(p)}&lt;/script&gt;を&lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;のp階微分とすると，
&lt;script type=&quot;math/tex&quot;&gt;\|f^{(p)}(\boldsymbol{x}) - f^{(p)}(\boldsymbol{y})\|_2 \leq L\|\boldsymbol{x}-\boldsymbol{y}\|_2 \ \forall \boldsymbol{x},\boldsymbol{y} \in Q&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;この時&lt;script type=&quot;math/tex&quot;&gt;f\in C^{k,p}_L(Q)&lt;/script&gt;はリプシッツ連続であるという．&lt;/p&gt;

&lt;p&gt;今，目的関数が&lt;script type=&quot;math/tex&quot;&gt;f \in C^{1,1}_L(\mathbb{R}^d)&lt;/script&gt;だとしましょう．この時，以下が成立します．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
|f(\boldsymbol{y})-f(\boldsymbol{x})-\langle f&#39;(\boldsymbol{x}),\boldsymbol{y}-\boldsymbol{x} \rangle| \leq \frac{L}{2}\|\boldsymbol{y}-\boldsymbol{x}\|_2^2 \ \cdots (1)
\end{align*}&lt;/script&gt;

&lt;p&gt;さて，再び勾配法による一回分の更新を考えましょう．
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{y}=\boldsymbol{x}-h\nabla f(\boldsymbol{x})&lt;/script&gt;とすると，(1)より，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
f(\boldsymbol{y}) &amp;\leq f(\boldsymbol{x}) + \langle \nabla f(\boldsymbol{x}), \boldsymbol{y}-\boldsymbol{x} \rangle + \frac{L}{2}\|\boldsymbol{y}-\boldsymbol{x}\|^2_2 \\
&amp;= f(\boldsymbol{x}) - h\left(1 - \frac{h}{2}L\right)\|\nabla f(\boldsymbol{x})\|^2_2
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;したがって，&lt;script type=&quot;math/tex&quot;&gt;h\left(1 - \frac{h}{2}L\right) \geq 0&lt;/script&gt;，つまり，&lt;script type=&quot;math/tex&quot;&gt;h \leq \frac{2}{L}&lt;/script&gt;であれば，&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{y}) \leq f(\boldsymbol{x})&lt;/script&gt;が言えます．
つまり，当たり前かもしれませんが，勾配法によって関数が単調に減少するかはステップサイズの決め方に依存するということです．
ここから，ステップサイズの決め方がいかに重要かがわかりますね．&lt;/p&gt;

&lt;p&gt;問題なのは&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;がわからないということです．
もっともナイーブなステップサイズの決定方法は&lt;script type=&quot;math/tex&quot;&gt;h_k = h \ \forall k=0,1,\ldots&lt;/script&gt;として，適当に&lt;script type=&quot;math/tex&quot;&gt;h&gt;0&lt;/script&gt;を決めてやることですが，これだと必ずしも&lt;script type=&quot;math/tex&quot;&gt;h \leq \frac{2}{L}&lt;/script&gt;となっている保証はありません．そこで，なんらかの工夫が必要です．&lt;/p&gt;

&lt;p&gt;基本的には，更新の際に，&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{y}) \leq f(\boldsymbol{x})&lt;/script&gt;となる&lt;script type=&quot;math/tex&quot;&gt;h&gt;0&lt;/script&gt;を選べば良いわけですが，どうやったら良いのでしょうか？
適当に&lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt;を決めましょう．この時，&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{y}) &gt; f(\boldsymbol{x})&lt;/script&gt;となってしまったとします．
この時の戦略は，&lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt;を大きくするか，小さくするかです．どうしたらいいでしょう？&lt;/p&gt;

&lt;p&gt;もしも，更新によって関数値が増加してしまう時，つまり&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{y})&gt;f(\boldsymbol{x})&lt;/script&gt;の時，ステップサイズが&lt;script type=&quot;math/tex&quot;&gt;h&gt;\frac{2}{L}&lt;/script&gt;となっていることがわかります．ここから，&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{y}) \leq f(\boldsymbol{x})&lt;/script&gt;となるまで&lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt;を小さくしていけば良いことがわかります．
これは，更新によって，局所解または最適解を通り過ぎてしまったので，通り過ぎない程度に引き戻すことに相当します．
こんな感じでステップサイズを決めれば，一応目的関数は単調に減少していきます．&lt;/p&gt;

&lt;p&gt;まとめると，勾配法を使う際に最低限考えなければならないことは，&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{x}_{k+1}) \leq f(\boldsymbol{x}_k)&lt;/script&gt;となるように更新することで，これはステップサイズの決定に委ねられる．ステップサイズは，&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{x}_{k+1}) \leq f(\boldsymbol{x}_k)&lt;/script&gt;を満たすように決めれば良いが，もしこれが満たされない場合はステップサイズを小さくしていけば良い．&lt;/p&gt;

&lt;p&gt;こんな感じですかね．実際は，ステップサイズの決め方にもGoldstein-Armijo ruleとか，いろいろあるのでそれを使えばいいんですけどね．&lt;/p&gt;
</description>
        <pubDate>Mon, 11 Jan 2016 06:20:07 +0900</pubDate>
        <link>http://nktmemoja.github.io/jekyll/update/2016/01/11/gradient-method.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/jekyll/update/2016/01/11/gradient-method.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>ハードマージンSupport Vector Machine (SVM)の定式化</title>
        <description>&lt;p&gt;&lt;a rel=&quot;nofollow&quot; href=&quot;http://www.amazon.co.jp/gp/product/4061529064/ref=as_li_ss_tl?ie=UTF8&amp;amp;camp=247&amp;amp;creative=7399&amp;amp;creativeASIN=4061529064&amp;amp;linkCode=as2&amp;amp;tag=nettodesyuu00-22&quot; target=&quot;_blank&quot;&gt;サポートベクトルマシン (機械学習プロフェッショナルシリーズ)&lt;/a&gt;&lt;img src=&quot;http://ir-jp.amazon-adsystem.com/e/ir?t=nettodesyuu00-22&amp;amp;l=as2&amp;amp;o=9&amp;amp;a=4061529064&quot; width=&quot;1&quot; height=&quot;1&quot; border=&quot;0&quot; alt=&quot;&quot; style=&quot;border:none !important; margin:0px !important;&quot; /&gt;
を読んでいます．
SVMについて，わかっている気になっていましたが，わかっていませんでした．
意外と奥が深いですね．というわけでその整理の意味も込めてのポスト．&lt;/p&gt;

&lt;p&gt;この記事ではハードマージンSVMを考えます．
ハードマージンSVMでは，与えられたデータは線形分離可能であると仮定します．
つまり，超平面&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{x})=\boldsymbol{w}^T \boldsymbol{x} + b&lt;/script&gt;で，与えられた訓練データがミスなく分離できることを仮定します．
このような超平面は複数存在すると考えられますが，
SVMでは，「マージンを最大化する超平面を求める」，というのはよくある説明ですね．&lt;/p&gt;

&lt;p&gt;ではまず，マージンの定義から入りましょう．
今，訓練データ&lt;script type=&quot;math/tex&quot;&gt;\{(\boldsymbol{x}_i,y_i)\}_{i=1}^n, \boldsymbol{x}_i \in \mathbb{R}^d, y_i \in \{-1,1\} \ \forall i=1, \ldots, n&lt;/script&gt;が与えられているとします．
マージンを，
超平面&lt;script type=&quot;math/tex&quot;&gt;f(\boldsymbol{x})=\boldsymbol{w}^T \boldsymbol{x} + b&lt;/script&gt;からもっとも近いサンプルまでの距離と定義します．
つまり，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
i^{*} = \mathop{\rm arg\,min}\limits_{1 \leq i \leq n} \ \frac{|\boldsymbol{w}^T \boldsymbol{x}_i + b|}{\|\boldsymbol{w}\|}
= \mathop{\rm arg\,min}\limits_{1 \leq i \leq n} \ |\boldsymbol{w}^T \boldsymbol{x}_i + b|
\end{align*}&lt;/script&gt;

&lt;p&gt;と定義すると，マージンは&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\frac{|\boldsymbol{w}^T \boldsymbol{x}_{i^{*}} + b|}{\|\boldsymbol{w}\|}
\end{align*}&lt;/script&gt;

&lt;p&gt;と表すことができます．
全ての訓練データを正しく分類しつつ，このマージンを最大化したいので，以下の最適化問題を解きます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\max_{\boldsymbol{w},b} &amp;\ \frac{|\boldsymbol{w}^T \boldsymbol{x}_{i^{*}} + b|}{\|\boldsymbol{w}\|} \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) &gt; 0 \ \forall i=1,\ldots ,n
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;分子が邪魔なので，これを以下のように書き換えます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\max_{\boldsymbol{w},b} &amp;\ \frac{1}{\|\boldsymbol{w}\|} \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) &gt; 0 \ \forall i=1,\ldots ,n \\
&amp;\ |\boldsymbol{w}^T \boldsymbol{x}_{i^{*}} + b |=1
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;二つの制約条件を一つにまとめると，以下のようになります．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\max_{\boldsymbol{w},b} &amp;\ \frac{1}{\|\boldsymbol{w}\|} \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1 \ \forall i=1,\ldots ,n \\
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;個人的にはここの変形が一番きつかったですね…．
なので軽く補足しときます．
以下の制約を書き換えていきます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
 y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) &gt; 0 \ \forall i=1,\ldots ,n \ \cdots (1) \\
 |\boldsymbol{w}^T \boldsymbol{x}_{i^{*}} + b |=1 \ \cdots (2)
\end{align}&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;i^{*}&lt;/script&gt;の定義から，(2)は以下のように書き換えられます．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\ |\boldsymbol{w}^T \boldsymbol{x}_{i} + b| \geq 1  \ \forall i=1,\ldots ,n \ \cdots (2&#39;)
\end{align}&lt;/script&gt;

&lt;p&gt;ここで，(1)と(2’)を合体させたいのですが，
&lt;script type=&quot;math/tex&quot;&gt;y_i(\boldsymbol{w}^T \boldsymbol{x}_{i} + b) = |\boldsymbol{w}^T \boldsymbol{x}_{i} + b|&lt;/script&gt;
を示すことができれば良さそうです．
ここで，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) = \left\{
\begin{array}
\boldsymbol{w}^T \boldsymbol{x}_i + b &amp; (y_i=1) \\
-(\boldsymbol{w}^T \boldsymbol{x}_i + b) &amp; (y_i=-1)
\end{array}
\right.
\end{align*}, %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
|\boldsymbol{w}^T \boldsymbol{x}_i + b| = \left\{
\begin{array}
\boldsymbol{w}^T \boldsymbol{x}_i + b &amp; (\boldsymbol{w}^T \boldsymbol{x}_i + b \geq 0) \\
-(\boldsymbol{w}^T \boldsymbol{x}_i + b) &amp; (\boldsymbol{w}^T \boldsymbol{x}_i + b &lt; 0)
\end{array}
\right.
\end{align*}, %]]&gt;&lt;/script&gt;

&lt;p&gt;ですが，(1)より，&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}^T \boldsymbol{x}_i + b \geq 0&lt;/script&gt; は成り立たず，この文脈では必ず
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}^T \boldsymbol{x}_i + b &gt; 0&lt;/script&gt;となります．&lt;/p&gt;

&lt;p&gt;なので，&lt;script type=&quot;math/tex&quot;&gt;y_i=1 \Leftrightarrow \boldsymbol{w}^T \boldsymbol{x}_i + b &gt; 0&lt;/script&gt;と
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
y_i=-1 \Leftrightarrow \boldsymbol{w}^T \boldsymbol{x}_i + b &lt; 0 %]]&gt;&lt;/script&gt;を示すことにします．
すごく簡単すぎて示す必要もないかもしれませんが…．&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;y_i=1&lt;/script&gt;の時，(1)より，&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}^T \boldsymbol{x}_i + b &gt; 0&lt;/script&gt;．
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}^T \boldsymbol{x}_i + b &gt; 0&lt;/script&gt;の時，(1)と&lt;script type=&quot;math/tex&quot;&gt;y_i \in \{-1,1\}&lt;/script&gt;より，&lt;script type=&quot;math/tex&quot;&gt;y_i=1&lt;/script&gt;．
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
y_i=-1 \Leftrightarrow \boldsymbol{w}^T \boldsymbol{x}_i + b &lt; 0 %]]&gt;&lt;/script&gt;も同様．&lt;/p&gt;

&lt;p&gt;よって，
&lt;script type=&quot;math/tex&quot;&gt;y_i(\boldsymbol{w}^T \boldsymbol{x}_{i} + b) = |\boldsymbol{w}^T \boldsymbol{x}_{i} + b|&lt;/script&gt;．&lt;/p&gt;

&lt;p&gt;そういうわけで，(2’)は，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\ y_i(\boldsymbol{w}^T \boldsymbol{x}_{i} + b) \geq 1  \ \forall i=1,\ldots ,n \ \cdots (2&#39;&#39;)
\end{align}&lt;/script&gt;

&lt;p&gt;これで，(1)と(2’‘)を合体できますね．
最後に最大化と最小化を書き換えて，ノルムを2乗すれば，よく見るハードマージンSVMの最適化問題の完成です：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\min_{\boldsymbol{w},b} &amp;\ \|\boldsymbol{w}\|^2 \\
s.t. &amp;\ y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1 \ \forall i=1,\ldots ,n 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;ここで，与えられたデータに対して，制約&lt;script type=&quot;math/tex&quot;&gt;y_i(\boldsymbol{w}^T \boldsymbol{x}_i + b) \geq 1 \ \forall i=1,\ldots ,n&lt;/script&gt;を満たす&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{w}&lt;/script&gt;と&lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;が存在しないかもしれません．
というより，現実問題ではそのような場合がほとんどだと考えられます．
そこで，ソフトマージンの考え方が出てきます．
これについてはまた後日書けたらと思います．&lt;/p&gt;
</description>
        <pubDate>Fri, 08 Jan 2016 00:30:29 +0900</pubDate>
        <link>http://nktmemoja.github.io/jekyll/update/2016/01/08/hardmarginsvmformulation.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/jekyll/update/2016/01/08/hardmarginsvmformulation.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>正例とラベル無しデータからの学習 (PU classification)</title>
        <description>&lt;p&gt;通常の2値分類問題では，正例と負例が与えられています． しかし扱う問題によっては，このようなデータを用意するのが困難な時があります． 例えば，抽出型のタスクです． 抽出型のタスクでは，抽出したい対象を正例と考えます． この場合の負例は「正例以外のデータ」と定義するほかありません． しかし，集めた正例に対し，それ以外のデータを負例と定義してしまうと， それ以外のデータに含まれる正例も負例として扱ってしまいます．&lt;/p&gt;

&lt;p&gt;このように負例を定義するのが難しい場合には，正例とラベルなしデータから学習する枠組み，PU classificationが有用です． PU classificationについては，Elkan and Noto 2008を参照していただければと思うのですが，少しだけ解説しておきます． 3つの確率変数&lt;script type=&quot;math/tex&quot;&gt;x,y,s&lt;/script&gt;を考えます．ここで，&lt;script type=&quot;math/tex&quot;&gt;x \in \mathbb{R}, y \in \{-1,1\}, s \in \{0,1\}&lt;/script&gt;だとします． &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;は入力，&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;はクラスラベル，そして&lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt;はデータがラベリングされるかどうかを表しています． 我々が欲しいのは，
&lt;script type=&quot;math/tex&quot;&gt;p(y|x)&lt;/script&gt;
ですが，PU classificationでは&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;は観測することができません． 我々のゴールは，&lt;script type=&quot;math/tex&quot;&gt;\{(x_i,s_i)\}_{i=1}^n&lt;/script&gt;から
&lt;script type=&quot;math/tex&quot;&gt;p(y|x)&lt;/script&gt;
を学習することです． 結果からいうと，2つの仮定をおくことで，&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y=1|x) = \frac{p(s=1|x)}{p(s=1|y=1)}&lt;/script&gt;

&lt;p&gt;と表せます．
&lt;script type=&quot;math/tex&quot;&gt;p(s=1|x)&lt;/script&gt;
は与えられたデータから推定できます． そして，
&lt;script type=&quot;math/tex&quot;&gt;p(s=1|y=1)&lt;/script&gt;
は開発データから推定できます． 詳しくはElkan and Noto 2008の2章にまとめられています． 今回はElkan and Noto 2008の手法を用いてPU classificationを行っていきます．&lt;/p&gt;

&lt;p&gt;では，以下のような正解データを考えましょう． &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-true_labeled.png&quot; alt=&quot;true_labeled.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;このデータに対して，実際に与えられるのは以下のようなデータです． &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-pu_data.png&quot; alt=&quot;pu_data.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;このデータに対して，まずは通常のロジスティック回帰を適用してみます． なお，今回は負例が多いので，交差確認法には正例側のF値を用います． 結果は以下のようになりました． &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-result_of_tradclf1.png&quot; alt=&quot;result_of_tradclf.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ご覧のように，全て負例だと予測してしまいました． 次に，PU classificationを適用してみます． &lt;img src=&quot;http://nktmemo.files.wordpress.com/2015/10/wpid-result_of_puclassification.png&quot; alt=&quot;result_of_puclassification.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;正例とラベルなしデータから，うまく分類境界を学習できていることがわかります．&lt;/p&gt;

&lt;p&gt;デモ用のコードは以下に載せておきますのでぜひ試してみてください． ちなみに，非線形な分類境界を表現するための&lt;a href=&quot;https://gist.github.com/nkt1546789/e41199340f7a42c515be&quot; title=&quot;rbfmodel_wrapper.py&quot;&gt;rbfmodel_wrapper.py&lt;/a&gt; と PU Classificationのための&lt;a href=&quot;https://gist.github.com/nkt1546789/9fbbf2f450779bde60c3&quot; title=&quot;puwrapper.py&quot;&gt;puwrapper.py&lt;/a&gt; も合わせてDLしてください．&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/nkt1546789/e9421f06ea3a62bfbb8c&quot; title=&quot;https://gist.github.com/nkt1546789/e9421f06ea3a62bfbb8c&quot;&gt;https://gist.github.com/nkt1546789/e9421f06ea3a62bfbb8c&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Thu, 29 Oct 2015 21:47:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/machine%20learning/2015/10/29/29214700.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/machine%20learning/2015/10/29/29214700.html</guid>
        
        <category>Machine Learning</category>
        
        <category>PU classification</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Word2Vecを使った単語間関係分類</title>
        <description>&lt;p&gt;単語間には様々な関係があります． 今回は，単語間の関係をWord2Vecで学習させようと思います． Word2Vecにはアナロジーを捉えられるという話があります． あの有名な，king - man + woman = queen というやつですね． これは，king - man = queen - womanとも書けます． つまり，2語間の差が関係を表しており， この例だと，kingとmanの関係とqueenとwomanの関係が同じであると捉えることができます．&lt;/p&gt;

&lt;p&gt;さて，Word2Vecで学習したベクトル表現を使うと，差ベクトルがうまいこと関係を表すと書きましたが， 必ずしもそうなっているとは限りません． 加えて，ユーザが扱いたい関係とWord2Vecで学習した関係が一致しているとも限りません． そこで，今回も例のごとく教師あり学習を使います． ユーザは教師データを通して，扱いたい関係をアルゴリズムに伝えることができます．&lt;/p&gt;

&lt;p&gt;最初からあまり多くの関係を対象にするのはしんどいので，今回はis-a, has-a関係のみに着目します． これは，僕の理解では，柔道 is-a スポーツ，スポーツ has-a 柔道みたいなものだと思っています． まずは&lt;a href=&quot;https://gist.github.com/nkt1546789/a3b3a4c166fc1c0486a1&quot; title=&quot;training data&quot;&gt;training data&lt;/a&gt;を用意します． is-aとhas-aは反対の関係になっていると思うので，has-aのデータだけ用意します． この中には (スポーツ，野球)というhas-a関係を表す順序対がリストで格納されています． リスト内の順序対に対して差ベクトルを計算し，一つのデータとして扱います．&lt;/p&gt;

&lt;p&gt;コードは以下のようになりました．&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;training&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;gensim.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LogisticRegressionCV&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/path/to/your/w2v_model&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ntr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ntr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ntr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Xtr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ytr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Xte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;yte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogisticRegressionCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Xtr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ytr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ypred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Xte&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yte&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ypred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; 0.99502487562189057&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;今回は厳密な実験はせずに，簡単に性能を見てみました． テストデータに対して，99%の精度を出すことができました． 以下簡単なテストデータへの予測例です．&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ypred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;has-a&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;is-a&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# results:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;ブルーベリー&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;果物&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;動物&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;モルモット&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;動物&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;ワタボウシタマリン&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;登山&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;ロデオ&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;動物&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;ユーラシアカワウソ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;フリーダイビング&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;競馬&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;スポーツ&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;ゴルフ&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;いかがでしょうか？うまく狙った関係が分類できていると思います． とりあえずはうまくいきました！これで成功です！ これがどこまで実用に耐えられるかはやってみないとわかりませんが．&lt;/p&gt;

</description>
        <pubDate>Tue, 27 Oct 2015 20:57:00 +0900</pubDate>
        <link>http://nktmemoja.github.io/machine%20learning/2015/10/27/27205700.html</link>
        <guid isPermaLink="true">http://nktmemoja.github.io/machine%20learning/2015/10/27/27205700.html</guid>
        
        <category>Machine Learning</category>
        
        <category>NLP</category>
        
        <category>python</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
  </channel>
</rss>
