---
layout: post
title:  "Laplacian Node Weighting (LNW)を用いてHTMLから本文を抽出する"
date: 2016-07-09 20:21:53 +0900
categories: jekyll update
---

## はじめに
前回

- <a href="http://nktmemoja.github.io/jekyll/update/2016/07/06/laplaciannodeweighting.html" target="_blank">ラプラス正則化を使った，半教師付きグラフノード重み付け</a>

というのを紹介してみました．以下これをLNW (Laplacian node weighting)と呼びます．
今回はこれを用いて，ウェブページ（HTML）から本文を抽出してみたいと思います．
このタスクは，本文抽出とかメインコンテンツ抽出 (Main content extraction)とか呼ばれています．
ウェブページは，自身のコンテンツだけでなく，ヘッダーフッター，メニュー，広告などのノイズも多く含んでいます．
最近では，広告配信業者がページの内容に応じて関連の高い広告を埋め込んでいたりするので，ウェブページの解析がより難しくなっているように思います...．
なので，ウェブページを解析するためには，これらを除去または，テキストへの重み付けが必要になります．

テキストというのは，DOMツリー内のテキストノードを指します．
HTMLはDOMツリーで表されます．
DOMツリー内には，エレメントノードとテキストノードが存在します．
エレメントノードとは，HTMLのタグに相当します．
テキストノードは普通のテキストを指します．


さて，LNWは半教師付き学習アルゴリズムですが，教師データが自動的に得られる場合があります．
その一例が，ウェブページです．
ウェブページは<meta>内にタイトルやディスクリプション，キーワードなどの重要な情報を持っています．
これにより，教師データがほぼ自動的に得られます．
ウェブページでなくとも，論文だと，タイトル・アブストラクトなどが得られますし，大体のテキストに適用できるのではないかと思います．

まず，ステップ1でLNWを使って，テキストノードに重み付けをします．
その後，その情報を元に単語に重みを付与していきます．

### テキストノードへの重み付け (LNW使用)
LNWは，隣接行列$$\mathbf{A}$$と，初期値$$\mathbf{u}$$を必要としますので，これを定義します．
まず，テキストノード内のテキストを文とみなしこれを重み付きグラフのノードだと考えます．
そして，ノード間のエッジの重みを，ノード間のテキストの類似度とします．
なので，$$A_{ij}$$は，テキストノード$$i$$のテキストと，テキストノード$$j$$のテキストとの類似度になります．
DOMツリーを対象のグラフとして直接使わないことに注意してください．
次に$$\mathbf{u}$$ですが，まず考えられるのが，タイトルに該当するテキストノードを1に，その他を0にするという方法です．
これだとほとんどが0になってしまうので，タイトルとの類似度を$$\mathbf{u}$$に設定し，少し情報を増やします．
つまり，$$u_i$$はタイトルと，テキストノード$$i$$との類似度です．
まとめると，まずタイトルは最重要であるとし，次にタイトルと似ているものは重要であるとします．
これを表現しているのが，$$\mathbf{u}$$です．
そして，各ノードは，内容が似ているノードとリンクすることにします．これを表現しているのが，$$\mathbf{A}$$となります．

### 単語への重み付け
ステップ1でテキストノードの重要度を計算した後，単語への重み付けを実行します．
今回採用するアイデアはシンプルで，**重要なテキストノードに出現する単語は重要である**というものです．
つまり，単語$$v$$への重み$$f(v)$$を以下で定義します．

$$
\begin{align*}
f(v) = \sum_{t \in T(v)} w(t) c(v, t)
\end{align*}
$$

ただし，$$T(v)$$は，単語$$v$$が出現するテキストノード集合，$$w(t)$$はステップ1で計算したテキストノード$$t$$への重み，
$$c(v, t)$$は，単語$$v$$のテキストノード$$t$$での出現回数です．


## 実験
実験してみました．
今回は結果をtf (term frequency)と比較します．
本当はtfidfと比較したいのですが，idfがコーパス依存なので，tfだけと比較します．

データは，ニュース記事とレビュー記事にします．ともにノイズが多いものを選びました．
ノイズというのは，ヘッダーフッター，メニュー，広告などを指します．
最近のウェブページはこのような多くのノイズを含んでいます．
最近では，広告配信業者がページの内容に応じて関連の高い広告を埋め込んでいたりするので，ウェブページの解析がより難しくなっているように思います...．

話がそれましたが，以下の二つのURLをデータとします．

- ニュース記事: <a href="http://gigazine.net/news/20160706-santa-susana-nuclear-disaster/" target="_blank">アメリカ初のメルトダウンで最大の原発事故にもかかわらず隠蔽された「サンタスザーナ野外実験所」での事故に見る危機対応の難しさ - GIGAZINE</a>
- レビュー記事: <a href="http://tabelog.com/shizuoka/A2201/A220102/22000892/dtlrvwlst/37192867/?lid=unpickup_review" target="_blank">『生しらす！』by 0141 : 和食処 するが蕎 - 蒲原/そば [食べログ]</a>

ニュース記事に対する結果を図1に示します．
なお，タイトルに出現する単語は表示していません．

<center>表1 </center>

|順位|テキスト|スコア|
|:--|:---|:--|
|1|0.221384|屋外料理のデザートに、スモーキーで甘い「りんごのグリル」はいかが？ ｜ ライフハッカー［日本版］|
|2|0.202427|屋外料理のデザートに、スモーキーで甘い「りんごのグリル」はいかが？|
|3|0.121461|ライフハッカー[日本版]|
|4|0.100682|私にとって、屋外でグリルといえば「肉」を即座に思い浮かべます。グリルでサイドメニューを作るという考えはほとんどなく、りんごをグリルするなど考えたこともないのですが、「Food52」は私のグリルの概念を変えるとっておきのアイデアをシェアしてくれました。|
|5|0.091922|料理術|
|6|0.090498|しましたが、どういうわけかりんごを紹介したことはありません。りんごはBBQにぴったりで、とってもおいしいサイドディッシュまたはデザートになり得るのです。|
|7|0.082355|ライフハッカーでもフルーツをグリルすることのメリットを紹介|
|8|0.057824|固い酸味のあるりんご（グラニースミスが最適です）の芯を抜き、半分に切って植物油かバターを表面に軽く塗ったら焼き目が付くまで中火で数分間グリルします。もっとフレーバーを加えるなら、事前にマリネするのも手です。（アイデアは下記のリンクを参照してください。）もしくはグリルする前に、ベーコンの油を塗るのもおすすめです。|
|9|0.029545|山形県産 りんご ご家庭用 サンふじ 約5kg(生食可/約13玉-20玉入り/時期により品種変更)|
|10|0.001901|\| Food 52|
|11|0.0|google+|
|12|0.0|Advertising|
|13|0.0|メディアジーンサイト|
|14|0.0|子育て|
|15|0.0|家電|
|16|0.0|ツール|
|17|0.0|文房具|
|18|0.0|住まい|
|19|0.0|お知らせ|
|20|0.0|健康|

<br/>
<center>表2</center>

|順位|テキスト|スコア|
|1|0.098203|統計だと、離婚率の低い結婚適齢期は「28～32歳」らしい｜ギズモード・ジャパン|
|2|0.075638|28～32歳までに結婚した夫婦が最も結婚生活が長く、離婚率が低い|
|3|0.069549|統計だと、離婚率の低い結婚適齢期は「28～32歳」らしい|
|4|0.069549|統計だと、離婚率の低い結婚適齢期は「28～32歳」らしい|
|5|0.069549|統計だと、離婚率の低い結婚適齢期は「28～32歳」らしい|
|6|0.069549|統計だと、離婚率の低い結婚適齢期は「28～32歳」らしい|
|7|0.066137|一般的には、結婚が遅い人ほど離婚率が低いと考えられていた|
|8|0.046431|ユタ大学で社会学を研究する|
|9|0.046153|Nick Wolfinger教授|
|10|0.046067|教授は、アメリカにおける初婚年齢と離婚率についてのデータを分析していた際、奇妙なグラフに気づいたそうです。よくみると、10代などの若い頃に結婚した人の離婚率は高いものの、その後減少していき、30代中盤頃から再度上昇。それ以降は、初婚年齢が40代中盤に向かうにつれ、どんどん上がっているのです。|
|11|0.043331|大学研究|
|12|0.04173|」との研究結果を発表しました。|
|13|0.040952|とのことですよ。教授、優しいな…。|
|14|0.034328|Wolfinger教授は、それ以外にも20代後半から30代前半が結婚に適している理由があるといいます。いわく、それ以降になると、ひとりで暮らすにも十分な|
|15|0.031018|結婚は勢い、って本当なのかもしれませんね…。|
|16|0.028509|ため、新たな発見となったとのこと。|
|17|0.020686|なお、大分過ぎた模様。|
|18|0.020686|は、統計学的には「|
|19|0.020409|サイエンス|
|20|0.009511|このメールマガジンでは、テクノロジーやサイエンス、それに紐づくカルチャーの情報を発信するWebサイト、ギズモード・ジャパンからのさまざまな情報をお届けしていきます。|

<center>
$$
  \begin{array}{ccc}
  &\\LNW&&&TF&\\\hline\hline
1&本体&0.00357727325233                    &投稿&0.0226666666667	 \\
2&os x&0.00357727325233					   &件&0.0217777777778		 \\
3&キーボードマウスモニタ&0.00351833385311  &imac&0.0213333333333	 \\
4&server&0.00349771570308				   &点&0.0204444444444		 \\
5&中古品&0.00346942400604				   &ssd&0.0133333333333		 \\
6&config&0.00332368147584				   &満足度&0.0115555555556	 \\
7&新着&0.00331818190656					   &k&0.0111111111111		 \\
8&mg&0.00329978507541					   &hdd&0.0102222222222		 \\
9&eq2&0.00327657575963					   &4k&0.00844444444444		 \\
10&step&0.0032732266988					   &動画&0.008				 \\
11&コストパフォーマンス&0.00325942990303   &m&0.008					 \\
12&mc&0.0032043406235					   &dupont&0.008			 \\
13&mgem&0.0032043406235					   &y&0.008					 \\
14&mac pro&0.00319763504244				   &購入&0.00755555555556	 \\
15&md&0.00318798286291					   &jesse&0.00666666666667	 \\
16&検索&0.00315393001144				   &価格&0.00622222222222	 \\
17&お知らせ&0.00315393001144			   &retina&0.00622222222222	 \\
18&利用規約&0.00315393001144			   &製品&0.00533333333333	 \\
19&a8&0.00308604905707					   &spec&0.00488888888889	 \\
20&搭載&0.00307764323933				   &編集&0.00488888888889    \\
\end{array}
$$

</center>
<center>図2: ニュース記事への適用結果 (青=真の重要語)</center>
<!--
このアルゴリズムにおける教師データは高い重みがついて欲しいノード集合なので，単語への重み付けの場合**高い重みがついて欲しい単語集合**になります．
これを$$V^{*}$$とします．

ウェブページはヘッダーフッター，メニュー，広告など多くのノイズを含んでいます．
最近では，広告配信業者がページの内容に応じて関連の高い広告を埋め込んでいたりするので，ウェブページの解析がより難しくなっているように思います．
しかしながら，**どんなにノイズが多くても，タイトル（とディスクリプション）は信頼できる**と考えられます．
というわけで，今回はタイトル（とディスクリプション）に含まれる単語集合を$$V^{*}$$とします．
もちろんウェブページだけでなく，一般の文書にはタイトルがあると思うので，大体適用できると思います．

LNWを実行するには，$$V^{*}$$の他に，隣接行列$$\mathbf{A}$$が必要です．
今回は，これを共起行列とします．**重要な単語と共起する単語は重要**といった具合です．
これは，PageRankをテキストに応用したTextRankなんかと同じですね．
まとめると，

- $$V^{*}$$: タイトル（とディスクリプション）に出現する単語集合
- $$\mathbf{A}$$: 共起行列

とします．

# 実験
定性評価してみます．
対象は，

1. メインコンテンツがテキストのページ (<a href="http://gigazine.net/news/20160706-santa-susana-nuclear-disaster/" target="_blank">http://gigazine.net/news/20160706-santa-susana-nuclear-disaster/</a>)
2. そうでないページ (

1は例えばニュース記事などです．
2は例えば商品紹介ページだったり，画像や動画メインのページです．


|順位| 単語 |スコア|
|:---|:-----------------:|:-----------|
1 | アメリカ政府 |0.0108775415988|
2 | 徹底的 |0.0103866765743|
3 | 回避 |0.0102489698956|
4 | 放射性物質 |0.00826735437213|
5 | 表 |0.00688558477851|
6 | カリフォルニア州 |0.00687599731351|
7 | 完成 |0.00666602490429|
8 | 地球外生命 |0.00666602490429|
9 | 完全 |0.00662327332437|
10| 探査 |0.00654949037057|
11| fast |0.00654949037057|
12| 電波望遠鏡 |0.00654949037057|
13| 世界 |0.00654949037057|
14| 1979年 |0.00639230509713|
15| 危険 |0.00608159886266|
16| 例 |0.00597026076084|
17| 運用 |0.00586509783247|
18| カリフォルニア大学 |0.00578271053574|
19| 時点| 0.00554026259777|
20| アクシデント| 0.00532353224794|

図1: Gigazineへの適用結果<br/>



# おわりに
今回は，グラフノードへの重み付けアルゴリズムをウェブページに応用してみました．
ウェブページの解析といったら，メインコンテンツ抽出がよく研究されています．
画像や動画メインのページだと，メインとなるDOM要素を特定して，その中にある画像や動画を抽出する必要があります．
今回の応用例は，DOM要素の単語に重みをつけて，その合計値などでスコアをつければメインコンテンツ抽出にも使えると思います．
ちなみに，今回のアルゴリズムはDOM構造に依存していないので，同一ドメイン内で，評価やパラメータチューニングが簡単に行えることも強みだと思います．
-->
